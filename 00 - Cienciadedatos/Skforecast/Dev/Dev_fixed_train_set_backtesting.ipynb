{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3ad12fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-22T10:33:31.967668Z",
     "start_time": "2022-02-22T10:33:31.965379Z"
    }
   },
   "source": [
    "# Backtesting with fixed training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8319fdb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:05:55.917324Z",
     "start_time": "2022-02-23T14:05:55.906568Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/javi/Documents/GitHub/Workingon/00 - Cienciadedatos/Skforecast/Dev')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "Path.cwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c69f06a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:05:56.232318Z",
     "start_time": "2022-02-23T14:05:56.211903Z"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.insert(1, '/home/javi/Documents/GitHub/skforecast')\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f64eeb2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:05:56.867187Z",
     "start_time": "2022-02-23T14:05:56.859051Z"
    }
   },
   "outputs": [],
   "source": [
    "# !pip uninstall skforecast -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "548b6eb0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T15:55:03.339861Z",
     "start_time": "2022-02-23T15:55:03.323709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Unit test __init__\n",
    "# ==============================================================================\n",
    "import pytest\n",
    "from pytest import approx\n",
    "from typing import Union, Tuple, Optional, Any\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import logging\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from skforecast.model_selection import backtesting_forecaster\n",
    "from skforecast.model_selection.model_selection import _get_metric\n",
    "from skforecast.model_selection.model_selection import _backtesting_forecaster_refit\n",
    "from skforecast.ForecasterAutoreg import ForecasterAutoreg\n",
    "from skforecast.ForecasterAutoregCustom import ForecasterAutoregCustom\n",
    "from skforecast.ForecasterAutoregMultiOutput import ForecasterAutoregMultiOutput\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de7273f7",
   "metadata": {},
   "source": [
    "# _Backtesting_forecaster_refit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55164755",
   "metadata": {},
   "source": [
    "## Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b35e5fb1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:07:24.265722Z",
     "start_time": "2022-02-23T14:07:24.232786Z"
    }
   },
   "outputs": [],
   "source": [
    "def _backtesting_forecaster_refit(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable],\n",
    "    initial_train_size: int,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    set_out_sample_residuals: Any='deprecated'\n",
    ") -> Tuple[np.array, pd.DataFrame]:\n",
    "    '''\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with re-fit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregMultiOutput\n",
    "        Forecaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "    \n",
    "    initial_train_size: int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "        \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'}\n",
    "\n",
    "        It callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "        \n",
    "    exog :panda Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "\n",
    "    interval: list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. If `None`, no\n",
    "        intervals are estimated. Only available for forecaster of type ForecasterAutoreg\n",
    "        and ForecasterAutoregCustom.\n",
    "            \n",
    "    n_boot: int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "\n",
    "    random_state: int, default 123\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "\n",
    "    in_sample_residuals: bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of\n",
    "        prediction error to create prediction intervals. If `False`, out_sample_residuals\n",
    "        are used if they are already stored inside the forecaster.\n",
    "\n",
    "    set_out_sample_residuals: 'deprecated'\n",
    "        Deprecated since version 0.4.2, will be removed on version 0.5.0.\n",
    "            \n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used for backtesting.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    metric_value: numpy ndarray shape (1,)\n",
    "        Value of the metric.\n",
    "\n",
    "    backtest_predictions: pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "            column pred = predictions.\n",
    "            column lower_bound = lower bound of the interval.\n",
    "            column upper_bound = upper bound interval of the interval.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    forecaster = deepcopy(forecaster)\n",
    "    if isinstance(metric, str):\n",
    "        metric = _get_metric(metric=metric)\n",
    "    backtest_predictions = []\n",
    "    \n",
    "    folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "    remainder = (len(y) - initial_train_size) % steps\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Information of backtesting process\")\n",
    "        print(f\"----------------------------------\")\n",
    "        print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(y) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {folds}\")\n",
    "        print(f\"    Number of steps per fold: {steps}\")\n",
    "        if remainder != 0:\n",
    "            print(f\"    Last fold only includes {remainder} observations.\")\n",
    "        print(\"\")\n",
    "        for i in range(folds):\n",
    "            train_size = initial_train_size + i * steps\n",
    "            print(f\"Data partition in fold: {i}\")\n",
    "            if i < folds - 1:\n",
    "                print(f\"    Training:   {y.index[0]} -- {y.index[train_size - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_size]} -- {y.index[train_size + steps - 1]}\")\n",
    "            else:\n",
    "                print(f\"    Training:   {y.index[0]} -- {y.index[train_size - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_size]} -- {y.index[-1]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    if folds > 50:\n",
    "        print(\n",
    "            f\"Forecaster will be fit {folds} times. This can take substantial amounts of time. \"\n",
    "            f\"If not feasible, try with `refit = False`. \\n\"\n",
    "        )\n",
    "\n",
    "    for i in range(folds):\n",
    "        # In each iteration (except the last one) the model is fitted before\n",
    "        # making predictions. The train size increases by `steps` in each iteration.\n",
    "        train_size = initial_train_size + i * steps\n",
    "        if exog is not None:\n",
    "            next_window_exog = exog.iloc[train_size:train_size + steps, ]\n",
    "\n",
    "        if interval is None:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[:train_size])\n",
    "                    pred = forecaster.predict(steps=steps)\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                    pred = forecaster.predict(steps=steps,exog=next_window_exog)\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[:train_size])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[:train_size])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[:train_size], exog=exog.iloc[:train_size, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "\n",
    "        backtest_predictions.append(pred)\n",
    "    \n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "            backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    metric_value = metric(\n",
    "                    y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "\n",
    "    return np.array([metric_value]), backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "56476a57",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:13:41.750716Z",
     "start_time": "2022-02-23T14:13:41.629909Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.Series(np.arange(40))\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 15\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d0ee2ef",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:35:08.169729Z",
     "start_time": "2022-02-23T14:35:08.152491Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 4 3\n"
     ]
    }
   ],
   "source": [
    "folds = int(np.ceil((len(y) - len(y_train)) / 4))\n",
    "remainder = (len(y) - len(y_train)) % 4\n",
    "print(len(y_train), folds, remainder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d2f6a3c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T14:13:56.225986Z",
     "start_time": "2022-02-23T14:13:55.664681Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 25\n",
      "Number of observations used for backtesting: 15\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 4\n",
      "    Last fold only includes 3 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 24\n",
      "    Validation: 25 -- 28\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 28\n",
      "    Validation: 29 -- 32\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 32\n",
      "    Validation: 33 -- 36\n",
      "Data partition in fold: 3\n",
      "    Training:   0 -- 36\n",
      "    Validation: 37 -- 39\n",
      "\n",
      "[9.85436667]      pred\n",
      "25  23.33\n",
      "26  23.33\n",
      "27  23.33\n",
      "28  23.33\n",
      "29  27.52\n",
      "30  27.52\n",
      "31  27.52\n",
      "32  27.52\n",
      "33  31.53\n",
      "34  31.53\n",
      "35  31.53\n",
      "36  31.53\n",
      "37  35.43\n",
      "38  35.43\n",
      "39  35.43\n"
     ]
    }
   ],
   "source": [
    "metric, predictions_backtest = backtesting_forecaster(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    refit      = True,\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "# print(metric, predictions_backtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24477e1a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e9b8364b",
   "metadata": {},
   "source": [
    "##  New"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2b76099a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T15:55:15.819227Z",
     "start_time": "2022-02-23T15:55:15.785503Z"
    }
   },
   "outputs": [],
   "source": [
    "def _backtesting_forecaster_refit_n(\n",
    "    forecaster,\n",
    "    y: pd.Series,\n",
    "    steps: int,\n",
    "    metric: Union[str, callable],\n",
    "    initial_train_size: int,\n",
    "    fixed_train_size: bool=False,\n",
    "    exog: Optional[Union[pd.Series, pd.DataFrame]]=None,\n",
    "    interval: Optional[list]=None,\n",
    "    n_boot: int=500,\n",
    "    random_state: int=123,\n",
    "    in_sample_residuals: bool=True,\n",
    "    verbose: bool=False,\n",
    "    set_out_sample_residuals: Any='deprecated'\n",
    ") -> Tuple[np.array, pd.DataFrame]:\n",
    "    '''\n",
    "    Backtesting of forecaster model with a re-fitting strategy. A copy of the  \n",
    "    original forecaster is created so it is not modified during the process.\n",
    "    \n",
    "    In each iteration:\n",
    "        - Fit forecaster with the training set.\n",
    "        - A number of `steps` ahead are predicted.\n",
    "        - The training set increases with `steps` observations.\n",
    "        - The model is re-fitted using the new training set.\n",
    "\n",
    "    In order to apply backtesting with re-fit, an initial training set must be\n",
    "    available, otherwise it would not be possible to increase the training set \n",
    "    after each iteration. `initial_train_size` must be provided.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : ForecasterAutoreg, ForecasterAutoregCustom, ForecasterAutoregMultiOutput\n",
    "        Forecaster model.\n",
    "        \n",
    "    y : pandas Series\n",
    "        Training time series values. \n",
    "    \n",
    "    initial_train_size: int\n",
    "        Number of samples in the initial train split. The backtest forecaster is\n",
    "        trained using the first `initial_train_size` observations.\n",
    "        \n",
    "    fixed_train_size: bool, default `False`\n",
    "        If True, train size doesn't increases but moves by `steps` in each iteration.\n",
    "        \n",
    "    steps : int\n",
    "        Number of steps to predict.\n",
    "        \n",
    "    metric : str, callable\n",
    "        Metric used to quantify the goodness of fit of the model.\n",
    "        \n",
    "        If string:\n",
    "            {'mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'}\n",
    "\n",
    "        It callable:\n",
    "            Function with arguments y_true, y_pred that returns a float.\n",
    "        \n",
    "    exog :panda Series, pandas DataFrame, default `None`\n",
    "        Exogenous variable/s included as predictor/s. Must have the same\n",
    "        number of observations as `y` and should be aligned so that y[i] is\n",
    "        regressed on exog[i].\n",
    "\n",
    "    interval: list, default `None`\n",
    "        Confidence of the prediction interval estimated. Sequence of percentiles\n",
    "        to compute, which must be between 0 and 100 inclusive. If `None`, no\n",
    "        intervals are estimated. Only available for forecaster of type ForecasterAutoreg\n",
    "        and ForecasterAutoregCustom.\n",
    "            \n",
    "    n_boot: int, default `500`\n",
    "        Number of bootstrapping iterations used to estimate prediction\n",
    "        intervals.\n",
    "\n",
    "    random_state: int, default 123\n",
    "        Sets a seed to the random generator, so that boot intervals are always \n",
    "        deterministic.\n",
    "\n",
    "    in_sample_residuals: bool, default `True`\n",
    "        If `True`, residuals from the training data are used as proxy of\n",
    "        prediction error to create prediction intervals. If `False`, out_sample_residuals\n",
    "        are used if they are already stored inside the forecaster.\n",
    "\n",
    "    set_out_sample_residuals: 'deprecated'\n",
    "        Deprecated since version 0.4.2, will be removed on version 0.5.0.\n",
    "            \n",
    "    verbose : bool, default `False`\n",
    "        Print number of folds and index of training and validation sets used for backtesting.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    metric_value: numpy ndarray shape (1,)\n",
    "        Value of the metric.\n",
    "\n",
    "    backtest_predictions: pandas Dataframe\n",
    "        Value of predictions and their estimated interval if `interval` is not `None`.\n",
    "            column pred = predictions.\n",
    "            column lower_bound = lower bound of the interval.\n",
    "            column upper_bound = upper bound interval of the interval.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    forecaster = deepcopy(forecaster)\n",
    "    if isinstance(metric, str):\n",
    "        metric = _get_metric(metric=metric)\n",
    "    backtest_predictions = []\n",
    "    \n",
    "    folds = int(np.ceil((len(y) - initial_train_size) / steps))\n",
    "    remainder = (len(y) - initial_train_size) % steps\n",
    "    \n",
    "    if verbose:\n",
    "        print(f\"Information of backtesting process\")\n",
    "        print(f\"----------------------------------\")\n",
    "        print(f\"Number of observations used for initial training: {initial_train_size}\")\n",
    "        print(f\"Number of observations used for backtesting: {len(y) - initial_train_size}\")\n",
    "        print(f\"    Number of folds: {folds}\")\n",
    "        print(f\"    Number of steps per fold: {steps}\")\n",
    "        if remainder != 0:\n",
    "            print(f\"    Last fold only includes {remainder} observations.\")\n",
    "        print(\"\")\n",
    "        for i in range(folds):\n",
    "            if fixed_train_size:\n",
    "                # The train size doesn't increase but moves by `steps` in each iteration.\n",
    "                train_idx_i = 0 + i * steps\n",
    "                train_idx_f = initial_train_size + i * steps\n",
    "            else:\n",
    "                # The train size increases by `steps` in each iteration.\n",
    "                train_idx_i = 0\n",
    "                train_idx_f = initial_train_size + i * steps\n",
    "            print(f\"Data partition in fold: {i}\")\n",
    "            if i < folds - 1:\n",
    "                print(f\"    Training:   {y.index[train_idx_i]} -- {y.index[train_idx_f - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_idx_f]} -- {y.index[train_idx_f + steps - 1]}\")\n",
    "            else:\n",
    "                print(f\"    Training:   {y.index[train_idx_i]} -- {y.index[train_idx_f - 1]}\")\n",
    "                print(f\"    Validation: {y.index[train_idx_f]} -- {y.index[-1]}\")\n",
    "        print(\"\")\n",
    "        \n",
    "    if folds > 50:\n",
    "        print(\n",
    "            f\"Forecaster will be fit {folds} times. This can take substantial amounts of time. \"\n",
    "            f\"If not feasible, try with `refit = False`. \\n\"\n",
    "        )\n",
    "\n",
    "    for i in range(folds):\n",
    "        # In each iteration (except the last one) the model is fitted before making predictions.\n",
    "        if fixed_train_size:\n",
    "            # The train size doesn't increases but moves by `steps` in each iteration.\n",
    "            train_idx_i = 0 + i * steps\n",
    "            train_idx_f = initial_train_size + i * steps\n",
    "        else:\n",
    "            # The train size increases by `steps` in each iteration.\n",
    "            train_idx_i = 0\n",
    "            train_idx_f = initial_train_size + i * steps\n",
    "            \n",
    "        if exog is not None:\n",
    "            next_window_exog = exog.iloc[train_size:train_size + steps, ]\n",
    "\n",
    "        if interval is None:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                    pred = forecaster.predict(steps=steps)\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                    pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                        pred = forecaster.predict(steps=steps)\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                        pred = forecaster.predict(steps=steps, exog=next_window_exog)\n",
    "        else:\n",
    "\n",
    "            if i < folds - 1:\n",
    "                if exog is None:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                else:\n",
    "                    forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                    pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "            else:    \n",
    "                if remainder == 0:\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "                else:\n",
    "                    # Only the remaining steps need to be predicted\n",
    "                    steps = remainder\n",
    "                    if exog is None:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                            )\n",
    "                    else:\n",
    "                        forecaster.fit(y=y.iloc[train_idx_i:train_idx_f], exog=exog.iloc[train_idx_i:train_idx_f, ])\n",
    "                        pred = forecaster.predict_interval(\n",
    "                                steps        = steps,\n",
    "                                exog         = next_window_exog,\n",
    "                                interval     = interval,\n",
    "                                n_boot       = n_boot,\n",
    "                                random_state = random_state,\n",
    "                                in_sample_residuals = in_sample_residuals\n",
    "                           )\n",
    "\n",
    "        backtest_predictions.append(pred)\n",
    "    \n",
    "    backtest_predictions = pd.concat(backtest_predictions)\n",
    "    if isinstance(backtest_predictions, pd.Series):\n",
    "        backtest_predictions = pd.DataFrame(backtest_predictions)\n",
    "\n",
    "    metric_value = metric(\n",
    "                    y_true = y.iloc[initial_train_size: initial_train_size + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "\n",
    "    return np.array([metric_value]), backtest_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "50f245a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T15:55:18.180008Z",
     "start_time": "2022-02-23T15:55:18.034886Z"
    }
   },
   "outputs": [],
   "source": [
    "y = pd.Series(np.arange(40))\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = RandomForestRegressor(random_state=123),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 15\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "eb0023a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T15:55:26.647616Z",
     "start_time": "2022-02-23T15:55:26.064598Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 25\n",
      "Number of observations used for backtesting: 15\n",
      "    Number of folds: 4\n",
      "    Number of steps per fold: 4\n",
      "    Last fold only includes 3 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 24\n",
      "    Validation: 25 -- 28\n",
      "Data partition in fold: 1\n",
      "    Training:   4 -- 28\n",
      "    Validation: 29 -- 32\n",
      "Data partition in fold: 2\n",
      "    Training:   8 -- 32\n",
      "    Validation: 33 -- 36\n",
      "Data partition in fold: 3\n",
      "    Training:   12 -- 36\n",
      "    Validation: 37 -- 39\n",
      "\n",
      "[10.59823333]      pred\n",
      "25  23.33\n",
      "26  23.33\n",
      "27  23.33\n",
      "28  23.33\n",
      "29  27.33\n",
      "30  27.33\n",
      "31  27.33\n",
      "32  27.33\n",
      "33  31.33\n",
      "34  31.33\n",
      "35  31.33\n",
      "36  31.33\n",
      "37  35.33\n",
      "38  35.33\n",
      "39  35.33\n"
     ]
    }
   ],
   "source": [
    "metric, predictions_backtest = _backtesting_forecaster_refit_n(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    fixed_train_size = True,\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric, predictions_backtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362d1a9e",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "6f372dd4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:31:30.187738Z",
     "start_time": "2022-02-23T17:31:30.160790Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
       "       0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
       "       0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
       "       0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
       "       0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
       "       0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
       "       0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
       "       0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
       "       0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
       "       0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601])"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fixtures Testing Backtesting\n",
    "# ==============================================================================\n",
    "np.random.seed(123)\n",
    "y_rnd = np.random.rand(50)\n",
    "exog_rnd = np.random.rand(50)\n",
    "exog_rnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "2f806850",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:32:54.127118Z",
     "start_time": "2022-02-23T17:32:54.109674Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures Testing Backtesting\n",
    "# ==============================================================================\n",
    "y = pd.Series(np.array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "       0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "       0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "       0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "       0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "       0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "       0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "       0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "       0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "       0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]))\n",
    "exog = pd.Series(np.array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "       0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "       0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "       0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "       0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "       0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "       0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "       0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "       0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "       0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]), name='exog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cd296c",
   "metadata": {},
   "source": [
    "### Mocked backtesting no exog no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "63d60e21",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:40:25.808349Z",
     "start_time": "2022-02-23T17:40:25.760394Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "[0.06598803]\n",
      "0.06598802629306816\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.38969292,\n",
       "       0.52778339, 0.49152015, 0.4841678 , 0.4076433 , 0.50904672,\n",
       "       0.50249462, 0.49232817])"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog no remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "361ce373",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:40:41.486818Z",
     "start_time": "2022-02-23T17:40:41.470958Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_no_exog_no_remainder = np.array(0.06598802629306816)\n",
    "assert metric_mocked_no_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                  0.52945466, 0.38969292, 0.52778339,\n",
    "                                                                                  0.49152015, 0.4841678 , 0.4076433 ,\n",
    "                                                                                  0.50904672, 0.50249462, 0.49232817])\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_no_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da339ca",
   "metadata": {},
   "source": [
    "### Mocked backtesting no exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "23eb923d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:41:12.967646Z",
     "start_time": "2022-02-23T17:41:12.917950Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "[0.06916732]\n",
      "0.06916732087926723\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.55717779, 0.43355138, 0.54969767, 0.52945466, 0.48308861,\n",
       "       0.5096801 , 0.49519677, 0.47997916, 0.49177914, 0.495797  ,\n",
       "       0.57738724, 0.44370472])"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting no exog yes remainder\n",
    "# ==============================================================================\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "13bf272e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:42:34.748250Z",
     "start_time": "2022-02-23T17:42:34.731196Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_no_exog_yes_remainder = np.array(0.06916732087926723)\n",
    "assert metric_mocked_no_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_no_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                   0.52945466, 0.48308861, 0.5096801 ,\n",
    "                                                                                   0.49519677, 0.47997916, 0.49177914,\n",
    "                                                                                   0.495797  , 0.57738724, 0.44370472])\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_no_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da323627",
   "metadata": {},
   "source": [
    "### Mocked backtesting yes exog no remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "7735e7a5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:47:32.156417Z",
     "start_time": "2022-02-23T17:47:32.114282Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 4\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 41\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 41\n",
      "    Validation: 42 -- 45\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 45\n",
      "    Validation: 46 -- 49\n",
      "\n",
      "[0.05663345]\n",
      "0.05663345135204598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.42295275,\n",
       "       0.46286083, 0.43618422, 0.43552906, 0.48687517, 0.55455072,\n",
       "       0.55577332, 0.53943402])"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog no remainder\n",
    "# ==============================================================================\n",
    "assert len(y) == len(exog)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 4,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "525617c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:47:33.026583Z",
     "start_time": "2022-02-23T17:47:33.009365Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_yes_exog_no_remainder = np.array(0.05663345135204598)\n",
    "assert metric_mocked_yes_exog_no_remainder == metric\n",
    "backtest_predictions_mocked_yes_exog_no_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098, \n",
    "                                                                                   0.46163343, 0.42295275, 0.46286083,\n",
    "                                                                                   0.43618422, 0.43552906, 0.48687517,\n",
    "                                                                                   0.55455072, 0.55577332, 0.53943402]\n",
    "                                                                                 )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_yes_exog_no_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28122d2",
   "metadata": {},
   "source": [
    "### Mocked backtesting yes exog yes remainder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "16ff95b7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:48:06.287820Z",
     "start_time": "2022-02-23T17:48:06.240168Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Information of backtesting process\n",
      "----------------------------------\n",
      "Number of observations used for initial training: 38\n",
      "Number of observations used for backtesting: 12\n",
      "    Number of folds: 3\n",
      "    Number of steps per fold: 5\n",
      "    Last fold only includes 2 observations.\n",
      "\n",
      "Data partition in fold: 0\n",
      "    Training:   0 -- 37\n",
      "    Validation: 38 -- 42\n",
      "Data partition in fold: 1\n",
      "    Training:   0 -- 42\n",
      "    Validation: 43 -- 47\n",
      "Data partition in fold: 2\n",
      "    Training:   0 -- 47\n",
      "    Validation: 48 -- 49\n",
      "\n",
      "[0.06172396]\n",
      "0.061723961096013524\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.59059622, 0.47257504, 0.53024098, 0.46163343, 0.50035119,\n",
       "       0.43595809, 0.4349167 , 0.42381237, 0.55165332, 0.53442833,\n",
       "       0.65361802, 0.51297419])"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mocked backtesting yes exog no remainder\n",
    "# ==============================================================================\n",
    "assert len(y) == len(exog)\n",
    "forecaster = ForecasterAutoreg(\n",
    "                regressor = LinearRegression(),\n",
    "                lags      = 3 \n",
    "             )\n",
    "forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "n_backtest = 12\n",
    "y_train = y[:-n_backtest]\n",
    "y_backtest = y[-n_backtest:]\n",
    "\n",
    "metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                    forecaster = forecaster,\n",
    "                                    y          = y,\n",
    "                                    exog       = exog,\n",
    "                                    initial_train_size = len(y_train),\n",
    "                                    steps      = 5,\n",
    "                                    metric     = 'mean_squared_error',\n",
    "                                    verbose    = True\n",
    "                               )\n",
    "\n",
    "print(metric)\n",
    "metric_value = _get_metric('mean_squared_error')(\n",
    "                    y_true = y.iloc[len(y_train) : len(y_train) + len(backtest_predictions)],\n",
    "                    y_pred = backtest_predictions['pred']\n",
    "                   )\n",
    "print(metric_value)\n",
    "backtest_predictions.pred.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "33c74b83",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:49:00.068156Z",
     "start_time": "2022-02-23T17:49:00.049963Z"
    }
   },
   "outputs": [],
   "source": [
    "metric_mocked_yes_exog_yes_remainder = np.array(0.061723961096013524)\n",
    "assert metric_mocked_yes_exog_yes_remainder == metric\n",
    "backtest_predictions_mocked_yes_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098,\n",
    "                                                                                    0.46163343, 0.50035119, 0.43595809,\n",
    "                                                                                    0.4349167 , 0.42381237, 0.55165332,\n",
    "                                                                                    0.53442833, 0.65361802, 0.51297419]\n",
    "                                                                                  )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "pd.testing.assert_frame_equal(backtest_predictions, backtest_predictions_mocked_yes_exog_yes_remainder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc101a1",
   "metadata": {},
   "source": [
    "### Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "aeb8375c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:52:45.997218Z",
     "start_time": "2022-02-23T17:52:45.959673Z"
    }
   },
   "outputs": [],
   "source": [
    "# Fixtures Testing Series\n",
    "# ==============================================================================\n",
    "# np.random.seed(123)\n",
    "# y = np.random.rand(50)\n",
    "# exog = np.random.rand(50)\n",
    "\n",
    "y = pd.Series(np.array([0.69646919, 0.28613933, 0.22685145, 0.55131477, 0.71946897,\n",
    "       0.42310646, 0.9807642 , 0.68482974, 0.4809319 , 0.39211752,\n",
    "       0.34317802, 0.72904971, 0.43857224, 0.0596779 , 0.39804426,\n",
    "       0.73799541, 0.18249173, 0.17545176, 0.53155137, 0.53182759,\n",
    "       0.63440096, 0.84943179, 0.72445532, 0.61102351, 0.72244338,\n",
    "       0.32295891, 0.36178866, 0.22826323, 0.29371405, 0.63097612,\n",
    "       0.09210494, 0.43370117, 0.43086276, 0.4936851 , 0.42583029,\n",
    "       0.31226122, 0.42635131, 0.89338916, 0.94416002, 0.50183668,\n",
    "       0.62395295, 0.1156184 , 0.31728548, 0.41482621, 0.86630916,\n",
    "       0.25045537, 0.48303426, 0.98555979, 0.51948512, 0.61289453]))\n",
    "exog = pd.Series(np.array([0.12062867, 0.8263408 , 0.60306013, 0.54506801, 0.34276383,\n",
    "       0.30412079, 0.41702221, 0.68130077, 0.87545684, 0.51042234,\n",
    "       0.66931378, 0.58593655, 0.6249035 , 0.67468905, 0.84234244,\n",
    "       0.08319499, 0.76368284, 0.24366637, 0.19422296, 0.57245696,\n",
    "       0.09571252, 0.88532683, 0.62724897, 0.72341636, 0.01612921,\n",
    "       0.59443188, 0.55678519, 0.15895964, 0.15307052, 0.69552953,\n",
    "       0.31876643, 0.6919703 , 0.55438325, 0.38895057, 0.92513249,\n",
    "       0.84167   , 0.35739757, 0.04359146, 0.30476807, 0.39818568,\n",
    "       0.70495883, 0.99535848, 0.35591487, 0.76254781, 0.59317692,\n",
    "       0.6917018 , 0.15112745, 0.39887629, 0.2408559 , 0.34345601]), name='exog')\n",
    "\n",
    "# Fixtures Testing Backtesting No exog No remainder\n",
    "# ==============================================================================\n",
    "metric_mocked_no_exog_no_remainder = np.array(0.06598802629306816)\n",
    "backtest_predictions_mocked_no_exog_no_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                  0.52945466, 0.38969292, 0.52778339,\n",
    "                                                                                  0.49152015, 0.4841678 , 0.4076433 , \n",
    "                                                                                  0.50904672, 0.50249462, 0.49232817]\n",
    "                                                                                 )\n",
    "                                                                }, index=np.arange(38, 50))\n",
    "# Fixtures Testing Backtesting No exog Yes remainder\n",
    "# ==============================================================================\n",
    "metric_mocked_no_exog_yes_remainder = np.array(0.06916732087926723)\n",
    "backtest_predictions_mocked_no_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.55717779, 0.43355138, 0.54969767,\n",
    "                                                                                   0.52945466, 0.48308861, 0.5096801 ,\n",
    "                                                                                   0.49519677, 0.47997916, 0.49177914,\n",
    "                                                                                   0.495797  , 0.57738724, 0.44370472]\n",
    "                                                                                  )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "# Fixtures Testing Backtesting Yes exog No remainder\n",
    "# ==============================================================================\n",
    "metric_mocked_yes_exog_no_remainder = np.array(0.05663345135204598)\n",
    "backtest_predictions_mocked_yes_exog_no_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098, \n",
    "                                                                                   0.46163343, 0.42295275, 0.46286083,\n",
    "                                                                                   0.43618422, 0.43552906, 0.48687517,\n",
    "                                                                                   0.55455072, 0.55577332, 0.53943402]\n",
    "                                                                                  )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "# Fixtures Testing Backtesting Yes exog Yes remainder\n",
    "# ==============================================================================\n",
    "metric_mocked_yes_exog_yes_remainder = np.array(0.061723961096013524)\n",
    "backtest_predictions_mocked_yes_exog_yes_remainder = pd.DataFrame({'pred':np.array([0.59059622, 0.47257504, 0.53024098,\n",
    "                                                                                    0.46163343, 0.50035119, 0.43595809,\n",
    "                                                                                    0.4349167 , 0.42381237, 0.55165332,\n",
    "                                                                                    0.53442833, 0.65361802, 0.51297419]\n",
    "                                                                                  )\n",
    "                                                                 }, index=np.arange(38, 50))\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with bactesting mocked. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.fit(y=y)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster = forecaster,\n",
    "                                        y          = y,\n",
    "                                        initial_train_size = len(y_train),\n",
    "                                        steps      = 4,\n",
    "                                        metric     = 'mean_squared_error',\n",
    "                                        verbose    = False\n",
    "                                   )  \n",
    "    expected_metric = metric_mocked_no_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_no_exog_no_remainder\n",
    "    assert expected_metric == metric\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with bactesting mocked. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, no exog, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.fit(y=y)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster = forecaster,\n",
    "                                        y          = y,\n",
    "                                        initial_train_size = len(y_train),\n",
    "                                        steps      = 5,\n",
    "                                        metric     = 'mean_squared_error',\n",
    "                                        verbose    = False\n",
    "                                   )  \n",
    "    expected_metric = metric_mocked_no_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_no_exog_yes_remainder\n",
    "    assert expected_metric == metric\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with bactesting mocked. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=4 (no remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster = forecaster,\n",
    "                                        y          = y,\n",
    "                                        exog       = exog,\n",
    "                                        initial_train_size = len(y_train),\n",
    "                                        steps      = 4,\n",
    "                                        metric     = 'mean_squared_error',\n",
    "                                        verbose    = False\n",
    "                                   )  \n",
    "    expected_metric = metric_mocked_yes_exog_no_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_yes_exog_no_remainder\n",
    "    assert expected_metric == metric\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)\n",
    "\n",
    "\n",
    "def test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked():\n",
    "    '''\n",
    "    Test output of _backtesting_forecaster_refit with bactesting mocked. \n",
    "    Regressor is LinearRegression with lags=3, Series y is mocked, exog is mocked, \n",
    "    12 observations to backtest, steps=5 (2 remainder), metric='mean_squared_error'\n",
    "    '''\n",
    "    forecaster = ForecasterAutoreg(regressor=LinearRegression(), lags=3)\n",
    "    forecaster.fit(y=y, exog=exog)\n",
    "\n",
    "    n_backtest = 12\n",
    "    y_train = y[:-n_backtest]\n",
    "\n",
    "    metric, backtest_predictions = _backtesting_forecaster_refit(\n",
    "                                        forecaster = forecaster,\n",
    "                                        y          = y,\n",
    "                                        exog       = exog,\n",
    "                                        initial_train_size = len(y_train),\n",
    "                                        steps      = 5,\n",
    "                                        metric     = 'mean_squared_error',\n",
    "                                        verbose    = False\n",
    "                                   )  \n",
    "    expected_metric = metric_mocked_yes_exog_yes_remainder\n",
    "    expected_backtest_predictions = backtest_predictions_mocked_yes_exog_yes_remainder\n",
    "    assert expected_metric == metric\n",
    "    pd.testing.assert_frame_equal(expected_backtest_predictions, backtest_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "515a3d0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-23T17:52:46.628423Z",
     "start_time": "2022-02-23T17:52:46.542493Z"
    }
   },
   "outputs": [],
   "source": [
    "test_output_backtesting_forecaster_refit_no_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_no_exog_yes_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_no_remainder_with_mocked()\n",
    "test_output_backtesting_forecaster_refit_yes_exog_yes_remainder_with_mocked()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a19127b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae7b745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "skforecast",
   "language": "python",
   "name": "skforecast"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "195.133px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
