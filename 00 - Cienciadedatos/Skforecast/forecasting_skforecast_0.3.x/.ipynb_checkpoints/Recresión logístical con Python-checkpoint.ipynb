{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "  <title>Regressión logística con Python</title>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font size=\"25\">Regressión logística con Python</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Joaquín Amat Rodrigo</b></center>\n",
    "\n",
    "<center><i>Junio, 2020</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre ciencia de datos: [**cienciadedatos.net**](https://cienciadedatos.net)\n",
    "+ [**Machine learning con Python y Scikit-learn**]()\n",
    "+ [**Regressión lineal con Python: Ridge y Lasso**]()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal es........."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regression es un método estadístico que attempts to model the relationship between a scalar response (or dependent variable) and one or more explanatory variables (or independent variables) by fitting a linear equation to observed data. The case of one explanatory variable is called simple linear regression.  For more than one explanatory variable, the process is called multiple linear regression.[\n",
    "\n",
    "For example, a modeler might want to relate the weights of individuals to their heights using a linear regression model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de regresión lineal (LM)\n",
    "<br>\n",
    "\n",
    "El modelo de regresión lineal (Legendre, Gauss, Galton y Pearson) considera que, dado un conjunto de observaciones, la media $\\mu$ de la variable respuesta $Y$ se relaciona de forma lineal con la o las variables regresoras $X$.\n",
    "\n",
    "$$\\mu = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + ... + \\beta_p x_{p}$$\n",
    "\n",
    "o en notación matricial (incorporando $\\beta_0$ en el vector $\\mathbf{\\beta}$:\n",
    "\n",
    "$$\\mu = \\mathbf{X}^T \\mathbf{\\beta}$$\n",
    "\n",
    "Ajustar el modelo consiste en estimar los valores de los coeficientes de regresión $\\hat{\\beta}$ y la varianza $\\hat{\\sigma}^2$ que maximizan la verosimilitud (*likelihood*) de los datos, es decir, los que dan lugar al modelo que con mayor probabilidad puede haber generado los datos observados. El método empleado con más frecuencia es el ajuste por mínimos cuadrados ordinarios (*OLS*): este método identifíca como mejor ajuste la linea que minimíza la suma de delas desviaciones verticales entre cada dato de entrenamiento y la linea , elevadas al cuadrado.\n",
    "\n",
    "$$\\hat{\\beta} = \\underset{\\beta_0,\\beta}{\\arg\\min} (Y - \\mathbf{X}^T \\mathbf{\\beta})^2$$\n",
    "\n",
    "$$\\hat{\\mu} = \\mathbf{X}^T \\mathbf{\\hat{\\beta}}$$\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{\\sum^n_{i=1} \\hat{\\epsilon}_i^2}{n-p} = \\frac{\\sum^n_{i=1} (y_i - \\hat{\\mu})^2}{n-p}$$\n",
    "\n",
    "donde $\\hat{\\epsilon}_i$ es la diferencia entre cada valor observado y la media estimada, $n$ es el número de observaciones y $p$ el número de predicciones.\n",
    "\n",
    "Es importante resaltar una característica de estos modelos. La estimación de la media $\\hat{\\mu}$ depende directamente del valor de los predictores $\\mathbf{X}$, sin embargo, la estimación de la varianza $\\hat{\\sigma}^2$ no depende directamente de los predictores, sino de $\\hat{\\mu}$. Para que sean válidas, deben cumplirse varias condiciones, dos de las cuales son:\n",
    "\n",
    "+ La variable respuesta $Y$ se tiene que distribuir de forma normal.\n",
    "\n",
    "+ La varianza $\\sigma^2$ debe de ser constante en todo el rango de la variable respuesta.\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos lineales generalizados (GLM)\n",
    "<br>\n",
    "\n",
    "El requisito de que la variable respuesta se distribuya de forma normal hace que el modelo de regresión lineal no sea aplicable a muchos problemas reales. Los modelos [GLM](https://es.wikipedia.org/wiki/Modelo_lineal_generalizado) (John Nelder y Robert Wedderburn) permiten superar esta limitación haciendo una abstracción a un modelo más genérico, en el que la variable respuesta puede seguir cualquier distribución de la [familia exponencial](https://en.wikipedia.org/wiki/Exponential_family) (Gaussian, Poisson, binomial…). Para conseguirlo, la media de la variable respuesta ya no está relacionada directamente con los predictores, sino que se hace a través de una función *link* $g(.)$. Por ejemplo, el modelo lineal generalizado es equivale al modelo de [regresión lineal por mínimos cuadrados](https://joaquinamatrodrigo.github.io/documentos/24_Correlacion_y_Regresion_lineal.html) cuando la función *link* es la identidad, o a la [regresión logística](https://joaquinamatrodrigo.github.io/documentos/27_Regresion_logistica_simple_y_multiple.html) cuando es binomial (*logit*).\n",
    "\n",
    "$$g(\\mu) = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + ... + \\beta_p x_{p}$$\n",
    "\n",
    "$$g(\\mu) = \\mathbf{X}^T \\mathbf{\\beta}$$\n",
    "\n",
    "\n",
    "Cuando se emplea una función *identidad*, la máxima verosimilitud equivale a minimizar la suma de errores cuadrados, lo que tiene una solución analítica. Para el resto de familias o cuando se emplea la regularización *L1*, no existe una solución analítica, por lo que se requiere un método de optimización iterativo como el *iteratively reweighted least squares (IRLSM)*, *L-BFGS*, método de Newton o descenso de gradiente.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regularización\n",
    "<br>\n",
    "\n",
    "Además, el modelo lineal generalizado puede incluir regularización durante su ajuste, por lo que también incluye los modelos [ridge regression](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html), [lasso](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html) y [elastic net](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html).\n",
    "\n",
    "**H2O** incorpora 3 tipos de regularización para los modelos *GLM* con el objetivo de evitar *overfitting*, reducir varianza y atenuar el efecto de la correlación entre predictores. Por lo general, aplicando regularización se consigue modelos con mayor poder predictivo (generalización).\n",
    "\n",
    "\n",
    "+ El modelo [lasso](https://rpubs.com/Joaquin_AR/242707) es un modelo lineal por mínimos cuadrados que incorpora una regularización que penaliza la suma del valor absolutos de los coeficientes de regresión $(||\\beta||_1 = \\sum_{k=1} ^p |\\beta_k|)$. A esta penalización se le conoce como *l1* y tiene el efecto de forzar a que los coeficientes de los predictores tiendan a cero. Dado que un predictor con coeficiente de regresión cero no influye en el modelo, *lasso* consigue seleccionar los predictores más influyentes. El grado de penalización está controlado por el hiperparámetro $\\lambda$. Cuando $\\lambda = 0$, el resultado es equivalente al de un modelo lineal por mínimos cuadrados ordinarios. A medida que $\\lambda$ aumenta, mayor es la penalización y más predictores quedan excluidos.\n",
    "\n",
    "+ El modelo [ridge](https://rpubs.com/Joaquin_AR/242707) es un modelo lineal por mínimos cuadrados que incorpora una regularización que penaliza la suma de los coeficientes elevados al cuadrado $(||\\beta||^2_2 = \\sum_{k=1} ^p \\beta^2_k)$. A esta penalización se le conoce como *l2* y tiene el efecto de reducir de forma proporcional el valor de todos los coeficientes del modelo pero sin que estos lleguen a cero. Al igual que *lasso*, el grado de penalización está controlado por el hiperparámetro $\\lambda$.\n",
    "\n",
    "La principal diferencia práctica entre *lasso* y *ridge* es que el primero consigue que algunos coeficientes sean exactamente cero, por lo que realiza selección de predictores, mientras que el segundo no llega a excluir ninguno. Esto supone una ventaja notable de *lasso* en escenarios donde no todos los predictores son importantes para el modelo y se desea que los menos influyentes queden excluidos. Por otro lado, cuando existen predictores altamente correlacionados (linealmente), *ridge* reduce la influencia de todos ellos a la vez y de forma proporcional, mientras que *lasso* tiende a seleccionar uno de ellos, dándole todo el peso y excluyendo al resto. En presencia de correlaciones, esta selección varía mucho con pequeñas perturbaciones (cambios en los datos de entrenamiento), por lo que, las soluciones de *lasso*, son muy inestables si los predictores están altamente correlacionados.\n",
    "\n",
    "Para conseguir un equilibrio óptimo entre estas dos propiedades, se puede emplear lo que se conoce como penalización *elastic net*, que combina ambas estrategias.\n",
    "\n",
    "+ El modelo *elastic net* incluye una regularización que combina la penalización *l1* y *l2* $(\\alpha \\lambda ||\\beta||_1 + \\frac{1}{2}(1- \\alpha)||\\beta||^2_2)$. El grado en que influye cada una de las penalizaciones está controlado por el hiperparámetro $\\alpha$. Su valor debe estar comprendido en el intervalo [0,1], cuando $\\alpha = 0$, **H2O** aplica *ridge regression* y cuando $\\alpha = 1$ aplica *lasso*. La combinación de ambas penalizaciones suele dar lugar a buenos resultados. Una estrategia frecuentemente utilizada es asignarle casi todo el peso a la penalización *l1* ($\\alpha$ muy próximo a 1) para conseguir seleccionar predictores y un poco a la *l2* para dar cierta estabilidad en el caso de que algunos predictores estén correlacionados.\n",
    "\n",
    "Encontrar el mejor modelo *GLM* implica identificar los valores óptimos de los hiperparámetros de regularización $\\alpha$ y $\\lambda$. Por defecto, **H2O** selecciona $\\alpha = 0.5$ y, con cada uno de ellos, analiza un rango de valores $\\lambda$. También es posible  hacer una búsqueda del valor óptimo de $\\alpha$ mediante un *grid seach*.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de ajuste\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se emplea una función *link* gausiana (con o sin regularización *L2*), la máxima verosimilitud equivale a minimizar la suma de errores cuadrados, lo que tiene una solución analítica. Para el resto de familias o cuando se emplea la regularización *L1*, no existe una solución analítica con la que encontrar la máxima verosimilitud, por lo que se requiere un método de optimización iterativo como el *iteratively reweighted least squares* (IRLSM), L-BFGS, método de Newton o descenso de gradiente.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensiones set de datos: (150, 4)\n",
      "Número de observaciones por grupo: [(0, 50), (1, 50), (2, 50)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"Dimensiones set de datos: {X.shape}\")\n",
    "print(f\"Número de observaciones por grupo: {list(zip(np.unique(y), np.bincount(y)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/miniconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:764: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_log = LogisticRegression(multi_class='auto', solver='lbfgs')\n",
    "modelo_log.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.41856958,  0.96684181, -2.52114755, -1.08412437],\n",
       "       [ 0.53117805, -0.3146598 , -0.19979472, -0.94884187],\n",
       "       [-0.11260847, -0.65218202,  2.72094227,  2.03296624]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# $ coeficientes por clase\n",
    "modelo_log.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x108 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6, 1.5))\n",
    "\n",
    "for ax, coef, classname in zip(axes, modelo_log.coef_, iris.target_names):\n",
    "    ax.barh(range(4), coef, height=.5, color=plt.cm.bwr_r(np.sign(coef)))\n",
    "    ax.set_xlim(modelo_log.coef_.min() - .1, modelo_log.coef_.max() + .1)\n",
    "\n",
    "    ax.set_title(classname)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "axes[0].set_yticks(range(4))\n",
    "axes[0].set_yticklabels(iris.feature_names)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "<br>\n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "API design for machine learning software: experiences from the scikit-learn project, Buitinck et al., 2013.\n",
    "    \n",
    "Uso de *pipes* y *ColumnTransformer*: https://www.dataschool.io/encoding-categorical-features-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hide_input": true,
    "remove_cell": true,
    "tags": [
     "\"hide_input\""
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".text_cell_render p {\n",
       "    text-align: justify;\n",
       "    font-family: 'Open Sans','Helvetica Neue',Helvetica,Arial,sans-serif;\n",
       "    #font-size: 16px;\n",
       "    line-height: 1.5;\n",
       "    font-weight: 400;\n",
       "    text-shadow: none;\n",
       "    color: #333333;\n",
       "    text-rendering: optimizeLegibility;\n",
       "    letter-spacing: +0.1px;\n",
       "    margin-bottom: 1.15rem;\n",
       "    font-size: 1.1em;\n",
       "}\n",
       "\n",
       "div.inner_cell {\n",
       "    margin-right: 5%;\n",
       "}\n",
       "\n",
       ".output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "    background-color: #f2f2f2;\n",
       "    font-family: monospace;\n",
       "    color: #a20505;\n",
       "    font-size: 15px;\n",
       "    font-size: 1em;\n",
       "}\n",
       "\n",
       ".rendered_html h1 {\n",
       "    padding-top: 50px;\n",
       "}\n",
       "\n",
       ".rendered_html h2 {\n",
       "    font-size: 30px\n",
       "    margin-top: 0;\n",
       "    font-size: 2.488em;\n",
       "}\n",
       "\n",
       ".rendered_html h3 {\n",
       "    font-size: 25px;\n",
       "}\n",
       "\n",
       ".rendered_html h4 {\n",
       "    font-size: 20px;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".text_cell_render p {\n",
    "    text-align: justify;\n",
    "    font-family: 'Open Sans','Helvetica Neue',Helvetica,Arial,sans-serif;\n",
    "    #font-size: 16px;\n",
    "    line-height: 1.5;\n",
    "    font-weight: 400;\n",
    "    text-shadow: none;\n",
    "    color: #333333;\n",
    "    text-rendering: optimizeLegibility;\n",
    "    letter-spacing: +0.1px;\n",
    "    margin-bottom: 1.15rem;\n",
    "    font-size: 1.1em;\n",
    "}\n",
    "\n",
    "div.inner_cell {\n",
    "    margin-right: 5%;\n",
    "}\n",
    "\n",
    ".output_png {\n",
    "        display: table-cell;\n",
    "        text-align: center;\n",
    "        vertical-align: middle;\n",
    "}\n",
    "\n",
    ".rendered_html code {\n",
    "    background-color: #f2f2f2;\n",
    "    font-family: monospace;\n",
    "    color: #a20505;\n",
    "    font-size: 15px;\n",
    "    font-size: 1em;\n",
    "}\n",
    "\n",
    ".rendered_html h1 {\n",
    "    padding-top: 50px;\n",
    "}\n",
    "\n",
    ".rendered_html h2 {\n",
    "    font-size: 30px\n",
    "    margin-top: 0;\n",
    "    font-size: 2.488em;\n",
    "}\n",
    "\n",
    ".rendered_html h3 {\n",
    "    font-size: 25px;\n",
    "}\n",
    "\n",
    ".rendered_html h4 {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work by  Joaquín Amat Rodrigo is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
