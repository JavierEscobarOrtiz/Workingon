{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<head>\n",
    "  <title>Regressión lineal con Python: Ridge y Lasso</title>\n",
    "</head>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font size=\"25\">Regressión lineal con Python: Ridge y Lasso</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Joaquín Amat Rodrigo</b></center>\n",
    "\n",
    "<center><i>Junio, 2020</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre ciencia de datos: [**cienciadedatos.net**](https://cienciadedatos.net)\n",
    "+ [**Machine learning con Python y Scikit-learn**]()\n",
    "+ [**Regressión logística con Python**]()\n",
    "\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La regresión lineal es un método estadístico que trata de modelar la relación lineal entre una variable continua (variable respuesta o dependiente) y una o más variables independientes (regresores o predictores) mediante el ajuste de una equación lineal. Se llama regresión lineal símple cuando solo hay una varriable independiente  y regresión lineal múltiple cuando hay más de una. Un ejemplo de regresión lineal simple sería modelar el peso de las personas en función de su peso.\n",
    "\n",
    "Dos de las principales implementaciones de regresión lineal en el lenguaje **Python** están disponibles en las librerías **Scikit-learn** y **Statsmodels**. A lo largo de este documento, se describen los fundaméntos teóricos de la regresión lineal, los principales aspectos prácticos a tener en cuenta y ejemplos de como crear los modelos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelos de regresión lineal (LM)\n",
    "<br>\n",
    "\n",
    "El modelo de regresión lineal (Legendre, Gauss, Galton y Pearson) considera que, dado un conjunto de observaciones, la media $\\mu$ de la variable respuesta $Y$ se relaciona de forma lineal con la o las variables regresoras $X$:\n",
    "\n",
    "$$\\mu_y = \\beta_0 + \\beta_1 x_{1} + \\beta_2 x_{2} + ... + \\beta_p x_{p}$$\n",
    "\n",
    "o en notación matricial (incorporando $\\beta_0$ en el vector $\\mathbf{\\beta}$):\n",
    "\n",
    "$$\\mu_y = \\mathbf{X}^T \\mathbf{\\beta}$$\n",
    "\n",
    "Otra definición equivalente que se encuentra con frecuencia en los libros de estadística es:\n",
    "\n",
    "$$Y=\\beta_0+\\beta_{1}X_1+\\beta_{2}X_2+\\beta_{n}X_n+\\epsilon$$\n",
    "\n",
    "+ $\\beta_{0}$: es la ordenada en el origen, el valor de la variable dependiente $Y$ cuando todos los predictores son cero.\n",
    "+ $\\beta_{i}$: es el efecto promedio que tiene sobre la variable dependiente $Y$ el incremento en una unidad de la variable predictora $X_{i}$, manteniéndose constantes el resto de variables. Se conocen como coeficientes parciales de regresión.\n",
    "+ $e$: es el residuo o error, la diferencia entre el valor observado y el estimado por el modelo. Recoge el efecto de todas aquellas variables que influyen en $Y$ pero que no se incluyen en el modelo como predictores.\n",
    "\n",
    "En la gran mayoría de casos, los valores $\\beta_{0}$ y $\\beta_{i}$ poblacionales se desconocen, por lo que, a partir de una muestra, se obtienen sus estimaciones $\\hat{\\beta}_{0}$ y $\\hat{\\beta}_{i}$.\n",
    "\n",
    "Ajustar el modelo consiste en estimar, a partir de los datos disponibles, los valores de los coeficientes de regresión $\\hat{\\beta}$ y la varianza $\\hat{\\sigma}^2$ que maximizan la verosimilitud (*likelihood*), es decir, los que dan lugar al modelo que con mayor probabilidad puede haber generado los datos observados. El método empleado con más frecuencia es el ajuste por mínimos cuadrados ordinarios (*OLS*): este método identifíca como mejor ajuste la linea que minimíza la suma de delas desviaciones verticales entre cada dato de entrenamiento y la linea , elevadas al cuadrado.\n",
    "\n",
    "$$\\hat{\\beta} = \\underset{\\beta_0,\\beta}{\\arg\\min} (Y - \\mathbf{X}^T \\mathbf{\\beta})^2$$\n",
    "\n",
    "$$\\hat{\\mu} = \\mathbf{X}^T \\mathbf{\\hat{\\beta}}$$\n",
    "\n",
    "$$\\hat{\\sigma}^2 = \\frac{\\sum^n_{i=1} \\hat{\\epsilon}_i^2}{n-p} = \\frac{\\sum^n_{i=1} (y_i - \\hat{\\mu})^2}{n-p}$$\n",
    "\n",
    "donde $n$ es el número de observaciones y $p$ el número de predicciones.\n",
    "\n",
    "Es importante resaltar dos característica de estos modelos:\n",
    "\n",
    "+ La magnitud de cada coeficiente parcial de regresión depende de las unidades en las que se mida la variable predictora a la que corresponde, por lo que su magnitud no está asociada con la importancia de cada predictor. Para poder determinar qué impacto tienen en el modelo cada una de las variables, se emplean los coeficientes parciales estandarizados, que se obtienen al estandarizar (sustraer la media y dividir entre la desviación estándar) las variables predictoras previo ajuste del modelo.\n",
    "\n",
    "+ La estimación de la media $\\hat{\\mu}$ depende directamente del valor de los predictores $\\mathbf{X}$, sin embargo, la estimación de la varianza $\\hat{\\sigma}^2$ no depende directamente de los predictores, sino de $\\hat{\\mu}$. Esto es importante a la hora de calcular los intervalos de confianza y está directamente relacionado con la condición de homocedasticidad (ver más adelante).\n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretación del modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scikit-learn\n",
    "<br>\n",
    "\n",
    "Un analista de deportes quiere saber si existe una relación entre el número de veces que batean los jugadores de un equipo de béisbol y el número de *runs* que consigue. En caso de existir y de establecer un modelo, podría predecir el resultado del partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equipos</th>\n",
       "      <th>bateos</th>\n",
       "      <th>runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>5659</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>5710</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>5563</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>5672</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>St.</td>\n",
       "      <td>5532</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   equipos  bateos  runs\n",
       "0    Texas    5659   855\n",
       "1   Boston    5710   875\n",
       "2  Detroit    5563   787\n",
       "3   Kansas    5672   730\n",
       "4      St.    5532   762"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equipos = [\"Texas\",\"Boston\",\"Detroit\",\"Kansas\",\"St.\",\"New_S.\",\"New_Y.\",\n",
    "           \"Milwaukee\",\"Colorado\",\"Houston\",\"Baltimore\",\"Los_An.\",\"Chicago\",\n",
    "           \"Cincinnati\",\"Los_P.\",\"Philadelphia\",\"Chicago\",\"Cleveland\",\"Arizona\",\n",
    "           \"Toronto\",\"Minnesota\",\"Florida\",\"Pittsburgh\",\"Oakland\",\"Tampa\",\n",
    "           \"Atlanta\",\"Washington\",\"San.F\",\"San.I\",\"Seattle\"]\n",
    "bateos = [5659,  5710, 5563, 5672, 5532, 5600, 5518, 5447, 5544, 5598,\n",
    "          5585, 5436, 5549, 5612, 5513, 5579, 5502, 5509, 5421, 5559,\n",
    "          5487, 5508, 5421, 5452, 5436, 5528, 5441, 5486, 5417, 5421]\n",
    "\n",
    "runs = [855, 875, 787, 730, 762, 718, 867, 721, 735, 615, 708, 644, 654, 735,\n",
    "        667, 713, 654, 704, 731, 743, 619, 625, 610, 645, 707, 641, 624, 570,\n",
    "        593, 556]\n",
    "\n",
    "datos = pd.DataFrame({'equipos': equipos, 'bateos': bateos, 'runs': runs})\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Representación gráfica\n",
    "\n",
    "El primer paso antes de generar un modelo de regresión es representar los datos para poder intuir si existe una relación y cuantificar dicha relación mediante un coeficiente de correlación. Si en este paso no se detecta la posible relación lineal, no tiene sentido seguir adelante generando un modelo lineal (se tendrían que probar otros modelos)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x276.48 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 3.84))\n",
    "\n",
    "datos.plot(\n",
    "    x    = 'bateos',\n",
    "    y    = 'runs',\n",
    "    c    = 'firebrick',\n",
    "    kind = \"scatter\",\n",
    "    ax   = ax\n",
    ")\n",
    "ax.set_title('Distribución de bateos y runs')\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficiente de correlación de Pearson:  0.6106270467206687\n",
      "P-value:  0.0003388351359791978\n"
     ]
    }
   ],
   "source": [
    "# Correlación lineal entre las dos variables\n",
    "# ------------------------------------------------------------------------------\n",
    "corr_test = pearsonr(x = datos['bateos'], y =  datos['runs'])\n",
    "print(\"Coeficiente de correlación de Pearson: \", corr_test[0])\n",
    "print(\"P-value: \", corr_test[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico y el test de correlación muestran una relación lineal, de intensidad considerable (r = 0.61) y significativa (p-value = 0.0003388). Tiene sentido intentar generar un modelo de regresión lineal con el objetivo de predecir el número de *runs* en función del número de bateos del equipo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo del modelo de regresión lineal simple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reparto de datos en train y test\n",
    "# ------------------------------------------------------------------------------\n",
    "X = datos[['bateos']]\n",
    "y = datos['runs']\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "                                        X.values.reshape(-1,1),\n",
    "                                        y.values.reshape(-1,1),\n",
    "                                        train_size   = 0.8,\n",
    "                                        random_state = 1234,\n",
    "                                        shuffle      = True\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo_lineal = LinearRegression()\n",
    "modelo_lineal.fit(X = X_train.reshape(-1, 1), y = y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-2367.7028413]\n",
      "Coeficiente: [('bateos', 0.5528713534479736)]\n",
      "Coeficiente de determinación R^2: 0.3586119899498744\n"
     ]
    }
   ],
   "source": [
    "print(\"Intercept:\", modelo_lineal.intercept_)\n",
    "print(\"Coeficiente:\", list(zip(X.columns, modelo_lineal.coef_.flatten(), )))\n",
    "print(\"Coeficiente de determinación R^2:\", modelo_lineal.score(X, y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statsmodels\n",
    "<br>\n",
    "\n",
    "La implementación de regresión lineal de **Statsmodels**, es más completa que la de **Scikitlearn** ya que, además de ajustar el modelo, permite calcular los test estadísticos y análisis necesarios para verificar que se cumplen las condiciones necesarias para dar por válido el modelo.\n",
    "\n",
    "Un analista de deportes quiere saber si existe una relación entre el número de veces que batean los jugadores de un equipo de béisbol y el número de *runs* que consigue. En caso de existir y de establecer un modelo, podría predecir el resultado del partido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>equipos</th>\n",
       "      <th>bateos</th>\n",
       "      <th>runs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Texas</td>\n",
       "      <td>5659</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Boston</td>\n",
       "      <td>5710</td>\n",
       "      <td>875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Detroit</td>\n",
       "      <td>5563</td>\n",
       "      <td>787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kansas</td>\n",
       "      <td>5672</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>St.</td>\n",
       "      <td>5532</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   equipos  bateos  runs\n",
       "0    Texas    5659   855\n",
       "1   Boston    5710   875\n",
       "2  Detroit    5563   787\n",
       "3   Kansas    5672   730\n",
       "4      St.    5532   762"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "equipos = [\"Texas\",\"Boston\",\"Detroit\",\"Kansas\",\"St.\",\"New_S.\",\"New_Y.\",\n",
    "           \"Milwaukee\",\"Colorado\",\"Houston\",\"Baltimore\",\"Los_An.\",\"Chicago\",\n",
    "           \"Cincinnati\",\"Los_P.\",\"Philadelphia\",\"Chicago\",\"Cleveland\",\"Arizona\",\n",
    "           \"Toronto\",\"Minnesota\",\"Florida\",\"Pittsburgh\",\"Oakland\",\"Tampa\",\n",
    "           \"Atlanta\",\"Washington\",\"San.F\",\"San.I\",\"Seattle\"]\n",
    "bateos = [5659,  5710, 5563, 5672, 5532, 5600, 5518, 5447, 5544, 5598,\n",
    "          5585, 5436, 5549, 5612, 5513, 5579, 5502, 5509, 5421, 5559,\n",
    "          5487, 5508, 5421, 5452, 5436, 5528, 5441, 5486, 5417, 5421]\n",
    "\n",
    "runs = [855, 875, 787, 730, 762, 718, 867, 721, 735, 615, 708, 644, 654, 735,\n",
    "        667, 713, 654, 704, 731, 743, 619, 625, 610, 645, 707, 641, 624, 570,\n",
    "        593, 556]\n",
    "\n",
    "datos = pd.DataFrame({'equipos': equipos, 'bateos': bateos, 'runs': runs})\n",
    "datos.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                   runs   R-squared (uncentered):                   0.988\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.988\n",
      "Method:                 Least Squares   F-statistic:                              2454.\n",
      "Date:                Tue, 30 Jun 2020   Prob (F-statistic):                    1.41e-29\n",
      "Time:                        10:31:00   Log-Likelihood:                         -172.28\n",
      "No. Observations:                  30   AIC:                                      346.6\n",
      "Df Residuals:                      29   BIC:                                      348.0\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "bateos         0.1257      0.003     49.534      0.000       0.120       0.131\n",
      "==============================================================================\n",
      "Omnibus:                        1.946   Durbin-Watson:                   0.778\n",
      "Prob(Omnibus):                  0.378   Jarque-Bera (JB):                1.531\n",
      "Skew:                           0.545   Prob(JB):                        0.465\n",
      "Kurtosis:                       2.807   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "modelo_lineal = sm.OLS(endog=datos['runs'], exog=datos['bateos'])\n",
    "modelo_lineal = modelo_lineal.fit()\n",
    "print(modelo_lineal.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Condiciones para la regresión lineal\n",
    "<br>\n",
    "\n",
    "Para que el modelo lineal resultante sea válido, deben cumplirse varias condiciones:\n",
    "\n",
    "**No colinialidad o multicolinialidad:**\n",
    "<br>\n",
    "\n",
    "En los modelos lineales múltiples los predictores deben ser independientes, no debe de haber colinialidad entre ellos. La colinialidad ocurre cuando un predictor está linealmente relacionado con uno o varios de los otros predictores del modelo. Como consecuencia de la colinialidad, no se puede identificar de forma precisa el efecto individual que tiene cada predictor sobre la variable respuesta, lo que se traduce en un incremento de la varianza de los  coeficientes  de  regresión  estimados  hasta  el  punto de que  resulta  prácticamente  imposible establecer su significancia estadística. Además, pequeños cambios en los datos provocan grandes cambios en las estimaciones de los coeficientes. Si bien la colinialidad propiamente dicha existe solo si el coeficiente de correlación simple o múltiple entre algunas de las variables independientes es 1, cosa que raramente ocurre en la realidad, es frecuente encontrar la llamada *casi-colinialidad* o *multicolinialidad no perfecta*.\n",
    "\n",
    "No existe un método estadístico concreto para determinar la existencia de colinialidad o multicolinialidad entre los predictores de un modelo de regresión, sin embargo, se han desarrollado numerosas reglas prácticas que tratan de determinar en qué medida afecta a la estimación y contraste de un modelo. Los pasos recomendados a seguir son:\n",
    "\n",
    "+ Si el coeficiente de determinación $R^2$ es alto pero ninguno de los predictores resulta significativo, hay indicios de colinialidad.\n",
    "\n",
    "+ Calcular una matriz de correlación en la que se estudia la relación lineal entre cada par de predictores. Es importante tener en cuenta que, a pesar de no obtenerse ningún coeficiente de correlación alto, no está asegurado que no exista multicolinialidad. Se puede dar el caso de tener una relación lineal casi perfecta entre tres o más variables y que las correlaciones simples entre pares de estas mismas variables no sean mayores que 0.5.\n",
    "\n",
    "+ Generar un modelo de regresión lineal simple entre cada uno de los predictores frente al resto. Si en alguno de los modelos el *coeficiente de determinación R^2^* es alto, estaría señalando a una posible colinialidad.\n",
    "\n",
    "+ Tolerancia (*TOL*) y Factor de Inflación de la Varianza (*VIF*). Se trata de dos parámetros que vienen a cuantificar lo mismo (uno es el inverso del otro). El *VIF* de cada predictor se calcula según la siguiente fórmula:\n",
    "\n",
    "$$VIF_{\\hat{\\beta}_j} = \\frac{1}{1 - R^{2}}$$ \n",
    "\n",
    "$$Tolerancia_{\\hat{\\beta}_j} = \\frac{1}{VIF_{\\hat{\\beta}_j}}$$\n",
    "\n",
    "Donde $R^2$ se obtiene de la regresión del predictor $X_j$ sobre los otros predictores. Esta es la opción más recomendada, los límites de referencia que se suelen emplear son:\n",
    "\n",
    "+ VIF = 1: ausencia total de colinialidad\n",
    "+ 1 < VIF < 5: la regresión puede verse afectada por cierta colinialidad.\n",
    "+ 5 < VIF < 10: causa de preocupación.\n",
    "+ El termino tolerancia es $1/VIF$ por lo que los límites recomendables están entre 1 y 0.1.\n",
    "<br>\n",
    "\n",
    "En caso de encontrar colinialidad entre predictores, hay dos posibles soluciones. La primera es excluir uno de los predictores problemáticos intentando conservar el que, a juicio del investigador, está influyendo realmente en la variable respuesta. Esta medida no suele tener mucho impacto en el modelo en cuanto a su capacidad predictiva ya que, al existir colinialidad, la información que aporta uno de los predictores es redundante en presencia del otro. La segunda opción consiste en combinar las variables colineales en un único predictor, aunque con el riesgo de perder su interpretación.\n",
    "\n",
    "Cuando se intenta establecer relaciones causa-efecto, la colinialidad puede llevar a conclusiones muy erróneas, haciendo creer que una variable es la causa cuando en realidad es otra la que está influenciando sobre ese predictor.\n",
    "<br><br>\n",
    "\n",
    "**Relación lineal entre los predictores numéricos y la variable respuesta** \n",
    "<br>\n",
    "\n",
    "Cada predictor numérico tiene que estar linealmente relacionado con la variable respuesta $Y$ mientras los demás predictores se mantienen constantes, de lo contrario no se deben introducir en el modelo. La forma más recomendable de comprobarlo es representando los residuos del modelo frente a cada uno de los predictores. Si la relación es lineal, los residuos se distribuyen de forma aleatoria entorno a cero. Estos análisis son solo aproximados, ya que no hay forma de saber si realmente la relación es lineal cuando el resto de predictores se mantienen constantes.\n",
    "<br><br>\n",
    "\n",
    "**Distribución normal de la variable respuesta** \n",
    "<br>\n",
    "\n",
    "La variable respuesta se tiene que distribuir de forma normal. Para comprobarlo se recurre a histogramas, a los cuantiles normales o a test de hipótesis de normalidad.\n",
    "<br><br>\n",
    "\n",
    "**Variabilidad constante de los residuos (homocedasticidad)** \n",
    "<br>\n",
    "\n",
    "La varianza de la variable respuesta debe ser constante en todo el rango de los predictores. Para comprobarlo suelen representarse los residuos del modelo frente a cada predictor. Si la varianza es constante, se distribuyen de forma aleatoria manteniendo una misma dispersión y sin ningún patrón específico. Una distribución cónica es un claro identificador de falta de homocedasticidad. También se puede recurrir a contrastes de homocedasticidad como el test de *Breusch-Pagan*.\n",
    "<br><br>\n",
    "\n",
    "**No autocorrelación (Independencia)** \n",
    "<br>\n",
    "\n",
    "Los valores de cada observación son independientes de los otros, esto es especialmente importante de comprobar cuando se trabaja con mediciones temporales. Se recomienda representar los residuos ordenados acorde al tiempo de registro de las observaciones, si existe un cierto patrón hay indicios de autocorrelación. También se puede emplear el test de hipótesis de Durbin-Watson.\n",
    "<br><br>\n",
    "\n",
    "**Valores atípicos, con alto leverage o influyentes** \n",
    "<br>\n",
    "\n",
    "Es importante identificar observaciones que sean atípicas o que puedan estar influenciando al modelo. La forma más fácil de detectarlas es a través de los residuos.\n",
    "<br><br>\n",
    "\n",
    "**Tamaño de la muestra**\n",
    "<br>\n",
    "\n",
    "No se trata de una condición de por sí pero, si no se dispone de suficientes observaciones, predictores que no son realmente influyentes podrían parecerlo. Un valor recomendación frecuente es que el número de observaciones sea como mínimo entre 10 y 20 veces el número de predictores del modelo.\n",
    "<br><br>\n",
    "\n",
    "**Parsimonia** \n",
    "<br>\n",
    "\n",
    "Este término hace referencia a que el mejor modelo es aquel capaz de explicar con mayor precisión la variabilidad observada en la variable respuesta empleando el menor número de predictores, por lo tanto, con menos asunciones.\n",
    "<br><br>\n",
    "\n",
    "La gran mayoría de condiciones se verifican utilizando los residuos, por lo tanto, se suele generar primero el modelo y posteriormente validar las condiciones. De hecho, el ajuste de un modelo debe verse como un proceso iterativo en el que se ajusta el modelo, se evalúan sus residuos y se mejora. Así hasta llegar a un modelo óptimo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significancia del modelo y predicores\n",
    "\n",
    "Cuando se dispone de múltiples predictores para crear un modelo, es recomendable estudiar si todos ellos son necesarios o si se puede conseguir un modelo más óptimo empleando solo algunos de ellos.\n",
    "\n",
    "Supóngase un modelo $M$ y otro modelo $m$, de menor tamaño, formado por un subconjunto de los predictores contenidos en $M$. Si la diferencia en el ajuste es muy pequeña, acorde al principio de parsimonia, el modelo $m$ es más adecuado. Es posible contrastar si la diferencia en ajuste es significativa mediante la comparación de los residuos. En concreto el estadístico empleado es:\n",
    "\n",
    "$$\\frac{RSS_m - RSS_M}{RSS_M}$$\n",
    "\n",
    "Para evitar que el tamaño del modelo influya en el contraste, se divide la suma de residuos cuadrados *RSS* de cada modelo entre sus grados de libertad. El estadístico resultante sigue una distribución $F$.\n",
    "\n",
    "$$\\frac{(RSS_m - RSS_M)/(df_m - df_M)}{RSS_M/(df_M)} \\sim F_{df_m-df_M, \\ df_M}$$\n",
    "\n",
    "donde $df$ son los grados de libertad del modelo, que equivalen al número de observaciones menos el número de predictores.\n",
    "<br><br>\n",
    "\n",
    "***F-test* para la significancia del modelo (todos sus predictores a la vez)**\n",
    "<br>\n",
    "\n",
    "Uno de los primeros resultados que hay que evaluar al ajustar un modelo es el resultado del test de significancia $F$. Este contraste responde a la pregunta de si el modelo en su conjunto es capaz de predecir la variable respuesta mejor de lo esperado por azar, o lo que es equivalente, si al menos uno de los predictores que forman el modelo contribuye de forma significativa. Para realizar este contraste se compara la suma de residuos cuadrados del modelo de interés con la del modelo sin predictores, formado únicamente por la media (también conocido como suma de cuadrados corregidos por la media, $TSS$).\n",
    "\n",
    "\n",
    "$$F = \\frac{(TSS - RSS)/(p-1)}{RSS/(n-p)}$$\n",
    "\n",
    "Con frecuencia, la hipótesis nula y alternativa de este test se describen como:\n",
    "\n",
    "+ $H_0$: $\\beta_1$ = ... = $\\beta_{p-1} = 0$\n",
    "+ $H_a$: al menos un $\\beta_i \\neq 0$ \n",
    "\n",
    "Si el test $F$ resulta significativo, implica que el modelo es útil, pero no que sea el mejor. Podría ocurrir que alguno de sus predictores no fuese necesario.\n",
    "<br><br>\n",
    "\n",
    "***F-test* para la significancia de un predictor individual $\\beta_i$**\n",
    "<br>\n",
    "\n",
    "A parte de estudiar la significancia de un modelo en su conjunto, es interesante poder conocer si un predictor en particular contribuye a dicho modelo o si podría ser eliminado. En este caso, la hipótesis que se desea contrastar es:\n",
    "$$H_0 : \\beta_i = 0$$\n",
    "$$H_0 : \\beta_i \\neq 0$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Significancia e intervalo de confianza para $\\beta_i$\n",
    "<br>\n",
    "\n",
    "En la mayoría de casos, aunque el estudio de regresión se aplica a una muestra, el objetivo último es obtener un modelo lineal que explique la relación entre las variables en toda la población. Esto significa que, el modelo generado, es una estimación de la relación poblacional a partir de la relación que se observa en la muestra y, por lo tanto, está sujeta a variaciones. Para cada uno de los coeficientes de la ecuación de regresión lineal simple ($\\beta_i$) se puede calcular su significancia (*p-value*) y su intervalo de confianza. El test estadístico más empleado es el [t-test](https://www.cienciadedatos.net/documentos/12_t-test) (existen alternativas no paramétricas).\n",
    "<br><br>\n",
    "\n",
    "El test de significancia para los coeficientes ($\\beta_i$) del modelo lineal considera como hipótesis:\n",
    "\n",
    "+ $H_0$: el predictor $X_i$ no contribuye al modelo en presencia del resto de predictores $\\beta_i = 0$. En el caso de regresión lineal simple, se puede interpretar también como que no existe relación lineal entre ambas variables por lo que la pendiente del modelo es cero $\\beta_1 = 0$.\n",
    "\n",
    "+ $H_a$: el predictor $X_i$ sí contribuye al modelo en presencia del resto de predictores $\\beta_i \\neq 0$. En el caso de regresión lineal simple, se puede interpretar también como que sí existe relación lineal entre ambas variables por lo que la pendiente del modelo es distinta de cero $\\beta_1 \\neq 0$.\n",
    "<br><br>\n",
    "\n",
    "**Cálculo del estadístico T y del *p-value*:**\n",
    "<br>\n",
    "\n",
    "$$t = \\frac{\\hat{\\beta_i}}{se(\\hat{\\beta_i})}$$\n",
    "\n",
    "donde\n",
    "\n",
    "$$SE(\\hat{\\beta}_i)^2 =  \\frac{\\sigma^2}{\\sum^n_{j=1}(x_{ij} -\\overline{x})^2}$$\n",
    "\n",
    "La varianza del error $\\sigma^2$ se estima a partir del *Residual Standar Error (RSE)*, que puede entenderse como la diferencia promedio que se desvía la variable respuesta de la verdadera línea de regresión. En el caso de regresión lineal simple, *RSE* equivale a:\n",
    "\n",
    "$$RSE = \\sqrt{\\frac{1}{n-2}RSS} = \\sqrt{\\frac{1}{n-2}\\sum^n_{i=1}(y_i -\\hat{y}_i)}$$\n",
    "\n",
    "+ Grados de libertad (*df*) = número observaciones - 2 = número observaciones -número predictores - 1\n",
    "\n",
    "+ *p-value* = P(|t| > valor calculado de t) \n",
    "<br><br>\n",
    "\n",
    "**Intervalos de confianza**\n",
    "<br>\n",
    "\n",
    "$$\\hat{\\beta}_i \\pm t_{df}^{\\alpha/2}  SE(\\hat{\\beta}_1)$$\n",
    "<br><br>\n",
    "\n",
    "Cuanto menor es el número de observaciones $n$, menor la capacidad para calcular el error estándar del  modelo. Como consecuencia, la exactitud de los coeficientes de regresión estimados se reduce. Esto tiene importancia sobretodo en la regresión múltiple.\n",
    "\n",
    "En los modelos generados con `statsmodels` se devuelve, junto con el valor de los coeficientes de regresión, el valor del estadístico $t$ obtenido para cada uno, los *p-value* y los intervalos de confianza correspondientes. Esto permite saber, además de las estimaciones, si son significativamente distintos de 0, es decir, si contribuyen al modelo.\n",
    "\n",
    "\n",
    "Para que los cálculos descritos anteriormente sean válidos, se tiene que asumir que los residuos son independientes y que se distribuyen de forma normal con media 0 y varianza $\\sigma^2$. Cuando la condición de normalidad no se satisface, existe la posibilidad de recurrir a los test de permutación para calcular significancia (*p-value*) y al *bootstrapping* para calcular intervalos de confianza.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bondad de ajuste del modelo\n",
    "<br>\n",
    "\n",
    "Una vez que se ha ajustado un modelo es necesario verificar su utilidad ya que, aun siendo la línea que mejor se ajusta a las observaciones de entre todas las posibles, el modelo puede ser malo. Las medidas más utilizadas para medir la calidad del ajuste son: *error estándar de los residuos*, *el test F* y *el coeficiente de determinación R^2^*.\n",
    "\n",
    "**Error estándar de los residuos (Residual Standar Error, RSE):** Mide la desviación promedio de cualquier punto estimado por el modelo respecto de la verdadera recta de regresión poblacional. Tiene las mismas unidades que la variable dependiente $Y$. Una forma de saber si el valor del *RSE* es grande consiste en dividirlo entre el valor medio de la variable respuesta, obteniendo así un % de la desviación.\n",
    "\n",
    "$$RSE = \\sqrt{\\frac{1}{n-p-1}RSS}$$\n",
    "En modelos lineales simples, dado que hay un único predictor $(n-p-1) = (n-2)$.\n",
    "\n",
    "**Coeficiente de determinación R^2^:** Describe la proporción de variabilidad observada en la variable dependiente *Y* explicada por el modelo y relativa a la variabilidad total. Su valor está acotado entre 0 y 1. Al ser adimensional presenta la ventaja frente al *RSE* de ser más fácil de interpretar.\n",
    "\n",
    "$$R^{2}=\\frac{\\text{Suma de cuadrados totales - Suma de cuadrados residuales}}{\\text{Suma de cuadrados totales}}=$$\n",
    "\n",
    "$$1-\\frac{\\text{Suma de cuadrados residuales}}{\\text{Suma de cuadrados totales}} = $$ \n",
    "\n",
    "$$1-\\frac{\\sum(\\hat{y_i}-y_i)^2}{\\sum(y_i-\\overline{y})^2}$$ \n",
    "\n",
    "En los  modelos de regresión lineal simple el valor de $R^2$ se corresponde con el cuadrado del *coeficiente de correlación de Pearson (r)* entre *X* e *Y*, no siendo así en regresión múltiple. Existe una modificación de $R^2$ conocida como $R^2-ajustado$ que se emplea principalmente en los modelos de regresión múltiple. Introduce una penalización cuantos más predictores se incorporan al modelo. En los modelos lineales simples no se emplea.\n",
    "    \n",
    "**Test F:** El test F es un test de hipótesis que considera como hipótesis nula que todos los coeficientes de correlación estimados son cero, frente a la hipótesis alternativa de que al menos uno de ellos no lo es. Se emplea en modelos de regresión múltiple para saber si al menos alguno de los predictores introducidos en el modelo contribuye de forma significativa. En modelos lineales simples, dado que solo hay un predictor, el *p-value* del test F es igual al *p-value* del *t-test* del predictor.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicción\n",
    "<br>\n",
    "\n",
    "Una vez generado un modelo válido, es posible predecir el valor de la variable dependiente $Y$ para nuevos valores de la variable predictora $X$. Es importante tener en cuenta que las predicciones deben, *a priori*,  limitarse al rango de valores dentro del que se encuentran las observaciones con las que se ha generado el modelo. Esto es importante puesto que solo en esta región se tiene certeza de que se cumplen las condiciones para que el modelo sea válido. Para calcular las predicciones se emplea la ecuación generada por regresión.\n",
    "\n",
    "Dado que el modelo generado se ha obtenido a partir de una muestra y por lo tanto las estimaciones de los coeficientes de regresión tienen un error asociado, también lo tienen los valores de las predicciones. Existen dos formas de medir la incertidumbre asociada con una predicción:\n",
    "\n",
    "+ **Intervalos de confianza:** Responden a la pregunta ¿Cuál es el intervalo de confianza del valor promedio de la variable respuesta $Y$ para un determinado valor $k$ del predictor $X$? \n",
    "\n",
    "$$\\hat{y} \\pm t_{\\alpha / 2, n - 2} \\sqrt{MSE \\left(\\frac{1}{n} + \\frac{(x_k - \\bar{x})^2}{\\sum(x_i - \\bar{x}^2)} \\right)}$$\n",
    "\n",
    "+ **Intervalos de predicción:** Responden a la pregunta ¿Dentro de que intervalo se espera que esté el valor de la variable respuesta $Y$ para un determinado valor $k$ del predictor $X$?\n",
    "\n",
    "$$\\hat{y} \\pm t_{\\alpha / 2, n - 2} \\sqrt{MSE \\left(1 + \\frac{1}{n} + \\frac{(x_k - \\bar{x})^2}{\\sum (x_i - \\bar{x})^2} \\right)}$$\n",
    "\n",
    "\n",
    "Si bien ambas preguntas parecen similares, la diferencia se encuentra en que los intervalos de confianza se aplican al valor promedio que se espera de $Y$ para un determinado valor de $X$, mientras que los intervalos de predicción no se aplican al promedio. Por esta razón los segundos siempre son más amplios que los primeros.\n",
    "\n",
    "En R se puede emplear la función `predict()` que recibe como argumento el modelo calculado, un *dataframe* con los nuevos valores del predictor $X$ y el tipo de intervalo (*confidence* o *prediction*).\n",
    "\n",
    "Una característica que deriva de la forma en que se calcula el margen de error en los intervalos de confianza y predicción, es que el intervalo se ensancha a medida que los valores de $X$ se aproximan a los extremos el rango observado.\n",
    "\n",
    "¿Por qué ocurre esto? Prestando atención a la ecuación del error estándar del intervalo de confianza, el numerador contiene el término $(x_k - \\bar{x})^2$ (lo mismo ocurre para el intervalo de predicción).\n",
    "\n",
    "$$\\sqrt{MSE \\left(\\frac{1}{n} + \\frac{(x_k - \\bar{x})^2}{\\sum(x_i - \\bar{x}^2)} \\right)}$$\n",
    "\n",
    "Este término se corresponde con la diferencia al cuadrado entre el valor $x_k$ para el que se hace la predicción y la media $\\bar{x}$ de los valores observados del predictor $X$. Cuanto más se aleje $x_k$ de $\\bar{x}$ mayor es el numerador y por lo tanto el error estándar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularización: Ridge y Lasso\n",
    "<br>\n",
    "\n",
    "Además, el modelo lineal generalizado puede incluir regularización durante su ajuste, por lo que también incluye los modelos [ridge regression](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html), [lasso](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html) y [elastic net](https://joaquinamatrodrigo.github.io/documentos/31_Seleccion_de_predictores_subset_selection_Ridge_Lasso_dimension_reduction.html).\n",
    "\n",
    "**Scikit-Learn** incorpora 3 tipos de regularización para los modelos *GLM* con el objetivo de evitar *overfitting*, reducir varianza y atenuar el efecto de la correlación entre predictores. Por lo general, aplicando regularización se consigue modelos con mayor poder predictivo (generalización).\n",
    "\n",
    "\n",
    "+ El modelo [lasso](https://rpubs.com/Joaquin_AR/242707) es un modelo lineal por mínimos cuadrados que incorpora una regularización que penaliza la suma del valor absolutos de los coeficientes de regresión $(||\\beta||_1 = \\sum_{k=1} ^p |\\beta_k|)$. A esta penalización se le conoce como *l1* y tiene el efecto de forzar a que los coeficientes de los predictores tiendan a cero. Dado que un predictor con coeficiente de regresión cero no influye en el modelo, *lasso* consigue seleccionar los predictores más influyentes. El grado de penalización está controlado por el hiperparámetro $\\lambda$. Cuando $\\lambda = 0$, el resultado es equivalente al de un modelo lineal por mínimos cuadrados ordinarios. A medida que $\\lambda$ aumenta, mayor es la penalización y más predictores quedan excluidos.\n",
    "\n",
    "+ El modelo [ridge](https://rpubs.com/Joaquin_AR/242707) es un modelo lineal por mínimos cuadrados que incorpora una regularización que penaliza la suma de los coeficientes elevados al cuadrado $(||\\beta||^2_2 = \\sum_{k=1} ^p \\beta^2_k)$. A esta penalización se le conoce como *l2* y tiene el efecto de reducir de forma proporcional el valor de todos los coeficientes del modelo pero sin que estos lleguen a cero. Al igual que *lasso*, el grado de penalización está controlado por el hiperparámetro $\\lambda$.\n",
    "\n",
    "La principal diferencia práctica entre *lasso* y *ridge* es que el primero consigue que algunos coeficientes sean exactamente cero, por lo que realiza selección de predictores, mientras que el segundo no llega a excluir ninguno. Esto supone una ventaja notable de *lasso* en escenarios donde no todos los predictores son importantes para el modelo y se desea que los menos influyentes queden excluidos. Por otro lado, cuando existen predictores altamente correlacionados (linealmente), *ridge* reduce la influencia de todos ellos a la vez y de forma proporcional, mientras que *lasso* tiende a seleccionar uno de ellos, dándole todo el peso y excluyendo al resto. En presencia de correlaciones, esta selección varía mucho con pequeñas perturbaciones (cambios en los datos de entrenamiento), por lo que, las soluciones de *lasso*, son muy inestables si los predictores están altamente correlacionados.\n",
    "\n",
    "Para conseguir un equilibrio óptimo entre estas dos propiedades, se puede emplear lo que se conoce como penalización *elastic net*, que combina ambas estrategias.\n",
    "\n",
    "+ El modelo *elastic net* incluye una regularización que combina la penalización *l1* y *l2* $(\\alpha \\lambda ||\\beta||_1 + \\frac{1}{2}(1- \\alpha)||\\beta||^2_2)$. El grado en que influye cada una de las penalizaciones está controlado por el hiperparámetro $\\alpha$. Su valor debe estar comprendido en el intervalo [0,1], cuando $\\alpha = 0$, **H2O** aplica *ridge regression* y cuando $\\alpha = 1$ aplica *lasso*. La combinación de ambas penalizaciones suele dar lugar a buenos resultados. Una estrategia frecuentemente utilizada es asignarle casi todo el peso a la penalización *l1* ($\\alpha$ muy próximo a 1) para conseguir seleccionar predictores y un poco a la *l2* para dar cierta estabilidad en el caso de que algunos predictores estén correlacionados.\n",
    "\n",
    "Encontrar el mejor modelo *GLM* implica identificar los valores óptimos de los hiperparámetros de regularización $\\alpha$ y $\\lambda$.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de ajuste\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando se emplea una función *link* gausiana (con o sin regularización *L2*), la máxima verosimilitud equivale a minimizar la suma de errores cuadrados, lo que tiene una solución analítica. Para el resto de familias o cuando se emplea la regularización *L1*, no existe una solución analítica con la que encontrar la máxima verosimilitud, por lo que se requiere un método de optimización iterativo como el *iteratively reweighted least squares* (IRLSM), L-BFGS, método de Newton o descenso de gradiente.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-6513a645c492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Gráfico con el valor de los coeficientes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodelo_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miris\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbwr_r\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msign\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "# Gráfico con el valor de los coeficientes\n",
    "fig, axes = plt.subplots(1, 3, figsize=(6, 1.5))\n",
    "\n",
    "for ax, coef, classname in zip(axes, modelo_log.coef_, iris.target_names):\n",
    "    ax.barh(range(4), coef, height=.5, color=plt.cm.bwr_r(np.sign(coef)))\n",
    "    ax.set_xlim(modelo_log.coef_.min() - .1, modelo_log.coef_.max() + .1)\n",
    "\n",
    "    ax.set_title(classname)\n",
    "    ax.set_frame_on(False)\n",
    "    ax.set_yticks(())\n",
    "    \n",
    "axes[0].set_yticks(range(4))\n",
    "axes[0].set_yticklabels(iris.feature_names)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apuntes varios\n",
    "<br>\n",
    "\n",
    "En este apartado recojo comentarios, definiciones y puntualizaciones que he ido encontrando en diferentes fuentes y que, o bien no he tenido tiempo de introducir en el cuerpo principal del documento, o que he considerado mejor mantenerlos al margen como información complementaria. \n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Origen del método de mínimos cuadrados y regresión\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "El método de mínimos cuadrados fue publicado en 1805 por Adrien Marie Legendre. El término *regresión* proviene de la publicación que hizo Francis Galton en 1985 llamada *Regression to mediocrity*. En ella, Galton emplea el método de mínimos cuadrados para demostrar que los hijos de parejas altas tienden a ser también altos pero no tanto como sus padres y que los hijos de parejas de poca estatura tienden a ser bajos pero no tanto como sus padres.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Significado de modelo lineal\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "En los modelos lineales los parámetros se incorporan en la ecuación de forma lineal, sin embargo, los predictores no tienen por qué ser lineales. La siguiente ecuación muestra un modelo lineal en el que el predictor $X_2$ no es lineal:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1X_1 + \\beta_2log(X_2) + \\epsilon$$\n",
    "En contraposición, el siguiente no es un modelo lineal:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1X_1^{\\beta_2} + \\epsilon$$\n",
    "\n",
    "En ocasiones, algunas relaciones no lineales pueden transformarse de forma que se pueden expresar de manera lineal:\n",
    "\n",
    "$$y = \\beta_0X_1^{\\beta_1}\\epsilon $$ \n",
    "$$log(y)=log(\\beta_0) + \\beta_1log(X_1) + log(\\epsilon)$$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimación de la varianza de un modelo lineal por mínimos cuadrados\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "La estimación de la varianza ($\\sigma^2$) de un modelo lineal obtenido por mínimos cuadrados es:\n",
    "$$\\sigma^2 = \\frac{RSS}{n - p}$$\n",
    "El termino *Residual Standar Error (RSE)*, es la raíz cuadrada de $\\sigma^2$:\n",
    "$$RSE = \\sqrt{\\frac{RSS}{n - p}}$$\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ventajas del método de mínimos cuadrados para estimar los coeficientes de un modelo lineal\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "Si bien existen alternativas al método de mínimos cuadrados para obtener la estimación de los coeficientes de correlación $\\hat{\\beta_i}$ de un modelo lineal, este presenta una serie de ventajas:\n",
    "\n",
    "+ Tiene una interpretación geométrica, lo que facilita su comprensión,\n",
    "+ Si los errores son independientes y se distribuyen de forma normal, su solución equivale a la estimación de máxima verosimilitud (*likelihood*).\n",
    "+ Los $\\hat{\\beta_i}$ son estimaciones insesgadas.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identidad (*identifiability*) o colinealidad\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "El método de mínimos cuadrados tiene una solución única solo si la matriz formada por los predictores es de rango máximo, es decir, que todas sus columnas (predictores) son linealmente independientes. En la práctica, esta condición de identidad suele violarse con frecuencia. Los siguientes son algunos escenarios en los que ocurre:\n",
    "\n",
    "+ Cuando uno de los predictores introducidos en el modelo es una transformación lineal o combinación de otros predictores presentes en el modelo. Por ejemplo, que la variable peso se introduzca en Kg y en libras o que se introduzcan como predictores el número de años de educación básica, el número de años de educación universitaria y el total de años de educación. Este problema se puede evitar estudiando la naturaleza de las variables disponibles y su relación.\n",
    "\n",
    "+ Sobresaturación del modelo, cuando hay más predictores que observaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precaución al evaluar la normalidad de los residuos por contraste de hipótesis\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "Que los residuos de un modelo de regresión lineal se distribuyan de forma normal es una condición necesaria para que la significancia (*p-value*) y los intervalos de confianza asociados a los predictores (calculados a partir de modelos teóricos) sean precisos. Con frecuencia, esta condición se evalúa con contrastes de hipótesis tales como el *Shapiro-Wilk test*. Cuando esto ocurre, es importante entender la relación entre *p-value* y tamaño de muestra. A mayor número de residuos mayor potencia tiene el test y, por lo tanto, pequeñas desviaciones de la normalidad resultan significativas. A su vez, el teorema del límite central indica que, cuanto mayor el tamaño de la muestra, más robustos son los resultados frente a desviaciones de la normalidad. Dadas estas propiedades, suele ser más recomendable evaluar la normalidad de los residuos de forma gráfica mediante representación de los cuantiles teóricos *qq-plot*.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identificación de outliers, observaciones con alto leverage y observaciones influyentes\n",
    "*Linear Models with R, by Julian J. Faraway*\n",
    "\n",
    "**Outlier u observación atípica:** Observaciones que no se ajustan bien al modelo. El valor real de la variable respuesta se aleja mucho del valor predicho, por lo que su residuo es excesivamente grande. En una representación bidimensional se corresponde con desviaciones en el eje $Y$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-4f094c2a1541>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-4f094c2a1541>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    datos    <- data.frame(x = 1:10, y = 1:10 + rnorm(10))\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "set.seed(123)\n",
    "datos    <- data.frame(x = 1:10, y = 1:10 + rnorm(10))\n",
    "modelo_1 <- lm(y ~ x, data = datos)\n",
    "\n",
    "observacion <- c(5.5, 12)\n",
    "modelo_2    <- lm(y ~ x, data = rbind(datos, observacion))\n",
    "plot(y ~ x, data = rbind(datos, observacion), pch = 19)\n",
    "points(5.5, 12, pch = 4, cex = 3, col = \"red\")\n",
    "legend(x = \"topleft\", legend = c(\"con outlier\", \"sin outlier\"), lty = c(2, 1))\n",
    "abline(modelo_1)\n",
    "abline(modelo_2, lty = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "<br>\n",
    "\n",
    "Scikit-learn: Machine Learning in Python, Pedregosa et al., JMLR 12, pp. 2825-2830, 2011.\n",
    "\n",
    "API design for machine learning software: experiences from the scikit-learn project, Buitinck et al., 2013.\n",
    "    \n",
    "Uso de *pipes* y *ColumnTransformer*: https://www.dataschool.io/encoding-categorical-features-in-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "code_folding": [],
    "hide_input": true,
    "remove_cell": true,
    "tags": [
     "\"hide_input\""
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       ".text_cell_render p {\n",
       "    text-align: justify;\n",
       "    font-family: 'Open Sans','Helvetica Neue',Helvetica,Arial,sans-serif;\n",
       "    #font-size: 16px;\n",
       "    line-height: 1.5;\n",
       "    font-weight: 400;\n",
       "    text-shadow: none;\n",
       "    color: #333333;\n",
       "    text-rendering: optimizeLegibility;\n",
       "    letter-spacing: +0.1px;\n",
       "    margin-bottom: 1.15rem;\n",
       "    font-size: 1.1em;\n",
       "}\n",
       "\n",
       "div.inner_cell {\n",
       "    margin-right: 5%;\n",
       "}\n",
       "\n",
       ".output_png {\n",
       "        display: table-cell;\n",
       "        text-align: center;\n",
       "        vertical-align: middle;\n",
       "}\n",
       "\n",
       ".rendered_html code {\n",
       "    background-color: #f2f2f2;\n",
       "    font-family: monospace;\n",
       "    color: #a20505;\n",
       "    font-size: 15px;\n",
       "    font-size: 1em;\n",
       "}\n",
       "\n",
       ".rendered_html h1 {\n",
       "    padding-top: 50px;\n",
       "}\n",
       "\n",
       ".rendered_html h2 {\n",
       "    font-size: 30px\n",
       "    margin-top: 0;\n",
       "    font-size: 2.488em;\n",
       "}\n",
       "\n",
       ".rendered_html h3 {\n",
       "    font-size: 25px;\n",
       "}\n",
       "\n",
       ".rendered_html h4 {\n",
       "    font-size: 20px;\n",
       "}\n",
       "\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    ".text_cell_render p {\n",
    "    text-align: justify;\n",
    "    font-family: 'Open Sans','Helvetica Neue',Helvetica,Arial,sans-serif;\n",
    "    #font-size: 16px;\n",
    "    line-height: 1.5;\n",
    "    font-weight: 400;\n",
    "    text-shadow: none;\n",
    "    color: #333333;\n",
    "    text-rendering: optimizeLegibility;\n",
    "    letter-spacing: +0.1px;\n",
    "    margin-bottom: 1.15rem;\n",
    "    font-size: 1.1em;\n",
    "}\n",
    "\n",
    "div.inner_cell {\n",
    "    margin-right: 5%;\n",
    "}\n",
    "\n",
    ".output_png {\n",
    "        display: table-cell;\n",
    "        text-align: center;\n",
    "        vertical-align: middle;\n",
    "}\n",
    "\n",
    ".rendered_html code {\n",
    "    background-color: #f2f2f2;\n",
    "    font-family: monospace;\n",
    "    color: #a20505;\n",
    "    font-size: 15px;\n",
    "    font-size: 1em;\n",
    "}\n",
    "\n",
    ".rendered_html h1 {\n",
    "    padding-top: 50px;\n",
    "}\n",
    "\n",
    ".rendered_html h2 {\n",
    "    font-size: 30px\n",
    "    margin-top: 0;\n",
    "    font-size: 2.488em;\n",
    "}\n",
    "\n",
    ".rendered_html h3 {\n",
    "    font-size: 25px;\n",
    "}\n",
    "\n",
    ".rendered_html h4 {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work by  Joaquín Amat Rodrigo is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
