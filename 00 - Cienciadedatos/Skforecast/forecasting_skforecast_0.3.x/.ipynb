{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center><font size=\"25\">Forecasting series temporales con Python y Scikitlearn</font></center></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><b>Joaquín Amat Rodrigo</b></center>\n",
    "\n",
    "<center><i>Febrero, 2020</i></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Más sobre ciencia de datos: [**cienciadedatos.net**](https://cienciadedatos.net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introducción\n",
    "<br>\n",
    "\n",
    "Una [serie temporal](https://es.wikipedia.org/wiki/Serie_temporal) (*time series*) es una sucesión de datos ordenados cronológicamente, espaciados a intervalos iguales o desiguales. \n",
    "\n",
    "El proceso de [*Forecasting*](https://en.wikipedia.org/wiki/Forecasting) consiste en predecir el valor futuro de una serie temporal, bien modelando la serie temporal únicamente en función de su comportamiento pasado (autorregresivo) o empleando otras variables externas a la serie temporal.\n",
    "\n",
    "A lo largo de este documento, se describe cómo utilizar modelos de regresión de **Scikit learn** para realizar *forecasting* sobre series temporales. Se van introduciendo de forma progresiva clases y funciones que automatizan los procesos necesarios para entrenar, predecir y selecionar modelos de *forecasting*.\n",
    "\n",
    "Al final del documento se encuentran las clases y funciones completas, con todas las funcionalidades mostradas.\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting\n",
    "<br>\n",
    "\n",
    "Cuando se trabaja con series temporales, raramente se necesita predecir el siguiente elemento de la serie ($t_{+1}$), sino todo un intervalo futuro o un punto alejado en el tiempo ($t_{+n}$). \n",
    "\n",
    "Dado que, para predecir el momento $t_{+2}$ se necesita el valor de $t_{+1}$, y $t_{+1}$ se desconoce, es necesario hacer predicciones recursivas en las que, cada nueva predicción, se basa en la predicción anterior. A este proceso se le conoce *recursive forecasting* o *multi-step forecasting* y es la principal diferencia respecto a los problemas de regresión convencionales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": true,
    "remove_cell": true,
    "tags": [
     "\"hide_input\""
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The text.latex.preview rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The mathtext.fallback_to_cm rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: Support for setting the 'mathtext.fallback_to_cm' rcParam is deprecated since 3.3 and will be removed two minor releases later; use 'mathtext.fallback : 'cm' instead.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The validate_bool_maybe_none function was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The savefig.jpeg_quality rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The keymap.all_axes rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_path rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n",
      "In /home/ubuntu/miniconda3/envs/cienciadedatos/lib/python3.7/site-packages/matplotlib/mpl-data/stylelib/_classic_test.mplstyle: \n",
      "The animation.avconv_args rcparam was deprecated in Matplotlib 3.3 and will be removed two minor releases later.\n"
     ]
    }
   ],
   "source": [
    "import gif\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "np.random.seed(1234)\n",
    "y = 10 * np.sin(np.arange(0, 10, 0.1))\n",
    "y = y + np.random.normal(loc=0.0, scale=4, size = len(y))\n",
    "datetime = pd.date_range(start='1/1/2020', periods=len(y), freq='D')\n",
    "datos = pd.Series(y, index=datetime)\n",
    "\n",
    "# fig, ax = plt.subplots(figsize=(9, 4))\n",
    "# datos[:-30].plot(ax=ax, c='c', marker='o', label='pasado',  zorder=3)\n",
    "# datos[-31:].plot(ax=ax, c='gray', label='futuro')\n",
    "# datos[-30:-15].plot(ax=ax, c='red', marker='o', linestyle='',\n",
    "#                        label='Valores predichos')\n",
    "# datos[[-15]].plot(ax=ax, c='red', marker='X', linestyle='', markersize=12,\n",
    "#                        label='Valor a predecir')\n",
    "# ax.set_title('Predecir un intervalo a futuro')\n",
    "# ax.legend();\n",
    "\n",
    "frames = []\n",
    "\n",
    "@gif.frame\n",
    "def custom_plot(i, j):\n",
    "    fig, ax = plt.subplots(figsize=(9, 4))\n",
    "    datos[:-30].plot(ax=ax, c='c', marker='o', label='pasado',  zorder=3)\n",
    "    datos[-31:].plot(ax=ax, c='gray', label='futuro')\n",
    "    \n",
    "    datos.iloc[len(datos)-30:i+1].plot(ax=ax, c='red', marker='o', linestyle='',\n",
    "                                       label='valor predicho')\n",
    "    \n",
    "    datos.iloc[[i]].plot(ax=ax, c='red', marker='X', linestyle='',\n",
    "                         markersize=12,label='valor a predecir')\n",
    "    ax.set_title(f'Forecasting recursivo (multi-step): (t+{j})')\n",
    "    ax.legend()\n",
    "    \n",
    "    return(ax)\n",
    "\n",
    "j=1\n",
    "for i in range(len(datos)-30, len(datos)):\n",
    "    frame = custom_plot(i, j)\n",
    "    frames.append(frame)\n",
    "    j+=1\n",
    "    \n",
    "gif.save(frames, './images/forecasting_multi-step.gif', duration=10, unit=\"s\", between=\"startend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![forecasting-python](./images/forecasting_multi-step.gif \"forecasting-python\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting autorregresivo con scikit learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La principal adaptación que se necesita hacer para aplicar modelos de [scikit learn](https://www.cienciadedatos.net/documentos/py06_machine_learning_python_scikitlearn.html) a problemas de *forecasting* es transformar la serie temporal\n",
    "en un matriz en la que, cada valor, está asociado a la ventana temporal (lags) que le preceden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![forecasting-python](./images/transform_timeseries.gif \"forecasting-python\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": true,
    "remove_cell": true,
    "tags": [
     "\"hide_input\""
    ]
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import HTML\n",
    "HTML(\"<center><font size='2.5'> <i>\" +\n",
    "\"Tranformación de una serie temporal en una matriz de lags y un vector con el valor de la serie que sigue a cada fila de la matriz.\" +\n",
    "     \"</i></font></center>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Librerías, Clases y Funciones\n",
    "<br>\n",
    "\n",
    "Además de las librerías necesarias, se incluyen la clase `Forecaster` que contine las funcionalidades necesarias para adaptar cualquier modelo de regresón de **Scikit learn** a problemas de *forecasting*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tratamiento de datos\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Gráficos\n",
    "# ==============================================================================\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Configuración warnings\n",
    "# ==============================================================================\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Clase Forecaster\n",
    "# ==============================================================================\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(asctime)-5s %(name)-15s %(levelname)-8s %(message)s', \n",
    "    level  = logging.INFO, # Nivel de los eventos que muestra el logger\n",
    ")\n",
    "\n",
    "class Forecaster():\n",
    "    '''\n",
    "    Convierte un regresor de scikitlearn en un forecaster recursivo (multi-step).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    n_lags : int\n",
    "        Número de lags utilizados cómo predictores.\n",
    "\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    last_lags : array-like, shape (1, n_lags)\n",
    "        Último valor de lags que ha visto el Forecaster al ser entrenado.\n",
    "        Se corresponde con el valor de los lags necesarios para predecir el\n",
    "        siguiente `step` después de los datos de entrenamiento.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, regressor, n_lags):\n",
    "        \n",
    "        self.regressor = regressor\n",
    "        self.n_lags    = n_lags\n",
    "        self.last_lags = None\n",
    "        \n",
    "    \n",
    "    def create_lags(self, y):\n",
    "        '''\n",
    "        Convierte una serie temporal en una matriz donde, cada valor de `y`,\n",
    "        está asociado a los lags temporales que le preceden.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaciones,)\n",
    "            Serie temporal de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        X_data : array-like, shape (nº observaciones, n_lags)\n",
    "            Matriz con el valor de los lags.\n",
    "        \n",
    "        y_data : array-like, shape (nº observaciones - n_lags)\n",
    "            Valores de la variable respuesta\n",
    "            \n",
    "        '''\n",
    "\n",
    "        # Número de divisiones\n",
    "        n_splits = len(y) - self.n_lags\n",
    "\n",
    "        # Matriz donde almacenar los valore de cada lag\n",
    "        X_data  = np.full(shape=(n_splits, self.n_lags), fill_value=np.nan, dtype= float)\n",
    "        y_data  = np.full(shape=(n_splits, 1), fill_value=np.nan, dtype= float)\n",
    "\n",
    "        for i in range(n_splits):\n",
    "\n",
    "            train_index = np.array(y.index[i : self.n_lags + i])\n",
    "            test_index  = y.index[self.n_lags + i]\n",
    "\n",
    "            X_data[i, :] = y[train_index]\n",
    "            y_data[i]    = y[test_index]\n",
    "\n",
    "        return X_data, y_data\n",
    "\n",
    "        \n",
    "    def fit(self, y):\n",
    "        '''\n",
    "        Entrenamiento del Forecaster\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaciones,)\n",
    "            Serie temporal de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self : object\n",
    "               objeto Forecaster entrenado\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        X_train, y_train = self.create_lags(y=y)\n",
    "        \n",
    "        self.regressor.fit(X=X_train, y=y_train)\n",
    "        \n",
    "        self.last_lags = np.hstack((X_train[-1, 1:], y_train[-1])).reshape(1, -1) \n",
    "        \n",
    "            \n",
    "    def predict(self, steps, X=None):\n",
    "        '''\n",
    "        Predicción recursiva en la que, cada nueva predicción, se utiliza como\n",
    "        predictor de la siguiente predicción.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "               \n",
    "        steps : int\n",
    "            Número de pasos a futuro que se predicen.\n",
    "            \n",
    "        X : array-like, shape (1, n_lags), default `None`\n",
    "            Valor de los predictores con los que se inicia el proceso iterativo\n",
    "            de predicción. Es decir, el valor de los lags para t+1.\n",
    "    \n",
    "            Si `X==None`, se utilizan como predictores iniciales los valores\n",
    "            almacenados en `self.last_lags`, y las predicciones se inician a \n",
    "            continuación de los datos de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        predicciones : np.array, shape (steps,)\n",
    "            Predicciones del modelo.\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        if X is None:\n",
    "            X = self.last_lags\n",
    "\n",
    "        predicciones = np.full(shape=steps, fill_value=np.nan)\n",
    "\n",
    "        for i in range(steps):\n",
    "\n",
    "            prediccion = self.regressor.predict(X).ravel()[0]\n",
    "            predicciones[i] = prediccion\n",
    "\n",
    "            # Actualizar valores de X con la nueva predicción\n",
    "            X = X.flatten()\n",
    "            X = np.append(X[1:], prediccion)\n",
    "            X = X.reshape(1, -1)\n",
    "\n",
    "\n",
    "        return(predicciones)\n",
    "    \n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        '''\n",
    "        Asignar nuevos valores a los parámetros del modelo scikitlearn contenido\n",
    "        en el Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Valor de los parámetros.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.regressor.set_params(**params)\n",
    "        \n",
    "        \n",
    "    def set_n_lags(self, n_lags):\n",
    "        '''\n",
    "        Asignar nuevo valor al atributo `n_lags` del Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_lags : int\n",
    "            Número de lags utilizados cómo predictores.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.n_lags = n_lags\n",
    "        \n",
    "        \n",
    "\n",
    "# Funciones auxiliares para validación de modelos y selección de hiperparámetros\n",
    "# ==============================================================================  \n",
    "\n",
    "def time_series_spliter(y, initial_train_size, steps, allow_incomplete_fold=True):\n",
    "    '''\n",
    "    \n",
    "    Dividir los índices de una serie temporal en múltiples pares de train-test.\n",
    "    Se mantiene el orden temporal de los datos y se incrementa en cada iteración\n",
    "    el conjunto de entrenamiento.\n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    y : array-like, shape (nº observaciones,)\n",
    "            Serie temporal de entrenamiento. \n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento en la partición inicial.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    train : ndarray\n",
    "        Índices del conjunto de entrenamiento.\n",
    "        \n",
    "    test : ndarray\n",
    "        Índices del conjunto de test.\n",
    "        \n",
    "    '''\n",
    "    \n",
    "  \n",
    "    folds     = (len(y) - initial_train_size) // steps  + 1\n",
    "    remainder = (len(y) - initial_train_size) % steps    \n",
    "    \n",
    "    for i in range(folds):\n",
    "          \n",
    "        if i < folds - 1:\n",
    "            train_end     = initial_train_size + i * steps    \n",
    "            train_indices = range(train_end)\n",
    "            test_indices  = range(train_end, train_end + steps)\n",
    "            \n",
    "        else:\n",
    "            if remainder != 0 and allow_incomplete_fold:\n",
    "                train_end     = initial_train_size + i * steps  \n",
    "                train_indices = range(train_end)\n",
    "                test_indices  = range(train_end, train_end + remainder)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        yield train_indices, test_indices\n",
    "        \n",
    "\n",
    "def ts_cv_forecaster(forecaster, y, initial_train_size, steps, metric,\n",
    "                     allow_incomplete_fold=True):\n",
    "    '''\n",
    "    Validación cruzada de un objeto Forecaster, manteniendo el orden temporal de\n",
    "    los datos e incrementando en cada iteración el conjunto de entrenamiento.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaciones)\n",
    "            Serie temporal de entrenamiento. \n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    ts_cv_results: \n",
    "        Valor de la métrica obtenido en cada partición.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ts_cv_results = []\n",
    "    \n",
    "    metrics = {\n",
    "        'neg_mean_squared_error': mean_squared_error,\n",
    "        'neg_mean_absolute_error': mean_absolute_error,\n",
    "        'neg_mean_absolute_percentage_error': mean_absolute_percentage_error\n",
    "    }\n",
    "    \n",
    "    metric = metrics[metric]\n",
    "    \n",
    "    splits = time_series_spliter(\n",
    "                y                     = y,\n",
    "                initial_train_size    = initial_train_size,\n",
    "                steps                 = steps,\n",
    "                allow_incomplete_fold = allow_incomplete_fold\n",
    "             )\n",
    "    \n",
    "    for train_index, test_index in splits:\n",
    "        \n",
    "        forecaster.fit(y=y.iloc[train_index])      \n",
    "        pred = forecaster.predict(steps=len(test_index))\n",
    "               \n",
    "        metric_value = metric(\n",
    "                            y_true = y.iloc[test_index],\n",
    "                            y_pred = pred\n",
    "                       )\n",
    "        \n",
    "        ts_cv_results.append(metric_value)\n",
    "                          \n",
    "    return np.array(ts_cv_results)\n",
    "\n",
    "\n",
    "def grid_search_forecaster(forecaster, y, param_grid, initial_train_size, steps,\n",
    "                           metric, n_lags_grid=None, allow_incomplete_fold=False,\n",
    "                           return_best=True):\n",
    "    '''\n",
    "    Búsqueda exhaustiva sobre los hiperparámetros de un Forecaster mediante\n",
    "    validación cruzada.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaciones,)\n",
    "        Serie temporal de entrenamiento. \n",
    "    \n",
    "    param_grid : dict\n",
    "        Valores de hiperparámetros sobre los que hacer la búsqueda\n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "        \n",
    "    n_lags_grid : array-like\n",
    "        Valores de `n_lags` sobre los que hacer la búsqueda.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "        \n",
    "    return_best : devuelve modifica el Forecaster y lo entrena con los mejores\n",
    "                  hiperparámetros encontrados.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    results: pandas.DataFrame\n",
    "        Valor de la métrica obtenido en cada combinación de hiperparámetros.\n",
    "\n",
    "    '''\n",
    "    n_lags_list = []\n",
    "    params_list = []\n",
    "    metric_list = []\n",
    "    \n",
    "    if n_lags_grid is None:\n",
    "        n_lags_grid = [forecaster.n_lags]\n",
    "    \n",
    "    param_grid =  list(ParameterGrid(param_grid))\n",
    "    \n",
    "    for n_lags in tqdm.tqdm(n_lags_grid, desc='loop n_lags_grid', position=0):\n",
    "        \n",
    "        forecaster.set_n_lags(n_lags)\n",
    "        \n",
    "        for params in tqdm.tqdm(param_grid, desc='loop param_grid', position=1, leave=False):\n",
    "\n",
    "            forecaster.set_params(**params)\n",
    "\n",
    "            cv_metrics = ts_cv_forecaster(\n",
    "                            forecaster = forecaster,\n",
    "                            y          = y,\n",
    "                            initial_train_size = initial_train_size,\n",
    "                            steps  = steps,\n",
    "                            metric = metric\n",
    "                        )\n",
    "            \n",
    "            n_lags_list.append(n_lags)\n",
    "            params_list.append(params)\n",
    "            metric_list.append(cv_metrics.mean())\n",
    "            \n",
    "    resultados = pd.DataFrame({\n",
    "                    'n_lags': n_lags_list,\n",
    "                    'params': params_list,\n",
    "                    'metric': metric_list})\n",
    "    \n",
    "    resultados = resultados.sort_values(by='metric', ascending=True)\n",
    "    \n",
    "    if return_best:\n",
    "        best_n_lags = resultados['n_lags'].iloc[0]\n",
    "        best_params = resultados['params'].iloc[0]\n",
    "        logging.info(\"Entrenando Forecaster con los mejores parámetros encontrados:\")\n",
    "        logging.info(f\"n_lags: {best_n_lags}, params: {best_params}\")\n",
    "        forecaster.set_n_lags(best_n_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "            \n",
    "    return resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos\n",
    "<br>\n",
    "\n",
    "Los datos empleados en los ejemplos de este document se han obtenido del magnifico libro [Forecasting: Principles and Practice by Rob J Hyndman and George Athanasopoulos](\"https://otexts.com/fpp2/\"). Representan el gasto mensual (millones de dolares) en fármacos con corticoides que tuvo el sistema de salud en Australia entre 1991 y 2008."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de datos\n",
    "# ==============================================================================\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/' \\\n",
    "      + 'Estadistica-machine-learning-python/master/data/elec.csv'\n",
    "datos = pd.read_csv(url, sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna *fecha* se ha almacenado como `strings`. Para convertirla en `Datetime`, se emplea la función `pd.to_datetime()`. Una vez en formato `Datetime`, y para hacer uso de las funcionalidades de pandas, se establece la columna *fecha* como índice. Además, dado que los datos son mensuales, se indica la frecuencia (*Monthly Started 'MS'*)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparación del dato\n",
    "# ==============================================================================\n",
    "datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y/%m/%d')\n",
    "datos = datos.set_index('fecha')\n",
    "datos = datos.rename(columns={'x': 'y'})\n",
    "datos = datos.asfreq('MS')\n",
    "datos = datos['y']\n",
    "datos = datos.sort_index()\n",
    "\n",
    "# Si el set de datos tiene valores NAN\n",
    "#datos.asfreq(freq='MS', fill_value=np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se utilizan los últimos 36 meses como conjunto de test para evaluar la capacidad predictiva del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación datos train-test\n",
    "# ==============================================================================\n",
    "steps = 36\n",
    "datos_train = datos[:-steps]\n",
    "datos_test  = datos[-steps:]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecaster\n",
    "<br>\n",
    "\n",
    "Se crea y entrena un modelo `Forecaster` a partir de un regresor `RandomForestRegressor` y ventana temporal de 12 lags."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar forecaster\n",
    "# ==============================================================================\n",
    "\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=RandomForestRegressor(random_state=123),\n",
    "                    n_lags=12\n",
    "                )\n",
    "\n",
    "forecaster_rf.fit(y=datos_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones\n",
    "<br>\n",
    "\n",
    "Una vez entrenado el modelo, se predicen los datos de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "predicciones = forecaster_rf.predict(steps=steps)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)\n",
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error predictores\n",
    "<br>\n",
    "\n",
    "Se cuentifica el error que comete el modelo al predecir los valores d ela serie temporal a futuro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning del modelo\n",
    "<br>\n",
    "\n",
    "El forecaster entrenado hasta el momento, ha utilizado una ventana temporal de 12 lags y un modelo Random Forest con los hiperparámetros por defecto. Sin embargo, no hay ninguna razón por la que estos valores sean los adecuados.\n",
    "\n",
    "Con el objetivo de identificar la mejor combinación de lags e hiperparámetros, se recurre a validación cruzada temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search de hiperparámetros\n",
    "# ==============================================================================\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=RandomForestRegressor(random_state=123),\n",
    "                    n_lags=12\n",
    "                 )\n",
    "\n",
    "param_grid = {'n_estimators': [100, 500, 1000],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "n_lags_grid = [5, 12, 20]\n",
    "\n",
    "resultados_grid = grid_search_forecaster(\n",
    "                        forecaster  = forecaster_rf,\n",
    "                        y           = datos_train,\n",
    "                        param_grid  = param_grid,\n",
    "                        n_lags_grid = n_lags_grid,\n",
    "                        steps       = 10,\n",
    "                        metric      = 'neg_mean_squared_error',\n",
    "                        initial_train_size    = int(len(datos_train)*0.5),\n",
    "                        allow_incomplete_fold = False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados Grid Search\n",
    "# ==============================================================================\n",
    "resultados_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen utilizando una ventana temporal de 20 lags y una configuración de random forest {'max_depth': 10, 'n_estimators': 1000}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "<br> \n",
    "\n",
    "Se entrena de nuevo un Forecaster con la configuración optima encontrada por validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar forecaster\n",
    "# ==============================================================================\n",
    "regressor = RandomForestRegressor(max_depth=10, n_estimators=1000, random_state=123)\n",
    "\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=regressor,\n",
    "                    n_lags=20\n",
    "                )\n",
    "\n",
    "forecaster_rf.fit(y=datos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "forecaster_rf.fit(y=datos_train)\n",
    "predicciones = forecaster_rf.predict(steps=steps)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)\n",
    "predicciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting con variables exógenas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supóngase que se dispone de información de otra variable, cuyo valor a futuro se conoce, y se quiere utilizar como predictor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(asctime)-5s %(name)-15s %(levelname)-8s %(message)s', \n",
    "    level  = logging.INFO, # Nivel de los eventos que se registran en el logger\n",
    ")\n",
    "\n",
    "class Forecaster():\n",
    "    '''\n",
    "    Combierte un regresor de scikitlearn en un forecaster recursivo (multi-step).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    n_lags : int\n",
    "        Número de lags utilizados cómo predictores.\n",
    "\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    last_lags : array-like, shape (1, n_lags)\n",
    "        Último valor de lags que ha visto el Forecaster al ser entrenado. Se\n",
    "        corresponde con el valor de los lags necesarios para predecir el\n",
    "        siguiente `step` después de los datos de entrenamiento.\n",
    "        \n",
    "    included_exog: bool, default `False`.\n",
    "        Si el Forecaster se ha entrenado utilizando variable/s exógenas.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, regressor, n_lags):\n",
    "        \n",
    "        self.regressor     = regressor\n",
    "        self.n_lags        = n_lags\n",
    "        self.last_lags     = None\n",
    "        self.included_exog = False\n",
    "        \n",
    "    \n",
    "    def create_lags(self, y):\n",
    "        '''\n",
    "        Combierte una serie temporal en una matriz donde, cada valor de y,\n",
    "        está asociado a los lags temporales que le preceden.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        X_data : array-like, shape (nº observaviones, n_lags)\n",
    "            Matriz con el valor de los lags.\n",
    "        \n",
    "        y_data : array-like, shape (nº observaviones - n_lags)\n",
    "            Valores de la variable respuesta.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        # Número de divisiones\n",
    "        n_splits = len(y) - self.n_lags\n",
    "\n",
    "        # Matriz donde almacenar los valore de cada lag\n",
    "        X_data  = np.full(shape=(n_splits, self.n_lags), fill_value=np.nan, dtype= float)\n",
    "        y_data  = np.full(shape=(n_splits, 1), fill_value=np.nan, dtype= float)\n",
    "\n",
    "        for i in range(n_splits):\n",
    "\n",
    "            train_index = np.array(y.index[i : self.n_lags + i])\n",
    "            test_index  = y.index[self.n_lags + i]\n",
    "\n",
    "            X_data[i, :] = y[train_index]\n",
    "            y_data[i]    = y[test_index]\n",
    "\n",
    "        return X_data, y_data\n",
    "\n",
    "        \n",
    "    def fit(self, y, exog=None):\n",
    "        '''\n",
    "        Entrenamiento del Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento.\n",
    "            \n",
    "        exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor/es.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self : object\n",
    "               objeto Forecaster entrenado.\n",
    "        \n",
    "        '''       \n",
    "        \n",
    "        X_train, y_train = self.create_lags(y=y)\n",
    "        \n",
    "        if exog is not None:\n",
    "            self.included_exog = True\n",
    "            self.regressor.fit(\n",
    "                # Se tiene que eliminar de exog las primeras self.n_lags\n",
    "                # posiciones ya que son NaN en X_train.\n",
    "                X=np.column_stack((X_train, exog[self.n_lags:])),\n",
    "                y=y_train\n",
    "            )\n",
    "        else:\n",
    "            self.regressor.fit(X=X_train, y=y_train)\n",
    "        \n",
    "        # Se guarda la última ventana temporal de lags de entrenamiento para que \n",
    "        # pueda utilizarse como predictores en la primera iteración del predict().\n",
    "        self.last_lags = np.hstack((X_train[-1, 1:], y_train[-1])).reshape(1, -1) \n",
    "        \n",
    "            \n",
    "    def predict(self, steps, X=None, exog=None):\n",
    "        '''\n",
    "        Proceso iterativo en la que, cada predicción, se utiliza como\n",
    "        predictor de la siguiente predicción.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "               \n",
    "        steps : int\n",
    "            Número de pasos a futuro que se predicen.\n",
    "            \n",
    "        X : array-like, shape (1, n_lags)\n",
    "            Valor de los predictores con los que se inicia el proceso iterativo\n",
    "            de predicción. Es decir, el valor de los lags para t+1.\n",
    "    \n",
    "            Si `X==None`, se utilizan como predictores iniciales los valores\n",
    "            almacenados en `self.last_lags`, y las predicciones se inician a \n",
    "            continuación de los datos de entrenamiento.\n",
    "            \n",
    "        exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor/es.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        predicciones : np.array, shape (nº observaciones)\n",
    "            Predicciones del modelo.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        if exog is None and self.included_exog:\n",
    "            raise Exception(\n",
    "                \"Forecaster entrenado con variable/s exogena/s. Se tiene \" \\\n",
    "                + \"que aportar esta misma variable en el predict().\"\n",
    "            )\n",
    "                \n",
    "        \n",
    "        if X is None:\n",
    "            X = self.last_lags\n",
    "            \n",
    "        if exog is not None:\n",
    "            if isinstance(exog, (pd.Series, list)):\n",
    "                exog = np.array(exog).reshape(-1,1)\n",
    "            \n",
    "\n",
    "        predicciones = np.full(shape=steps, fill_value=np.nan)\n",
    "\n",
    "        for i in range(steps):\n",
    "            if exog is None:\n",
    "                prediccion = self.regressor.predict(X=X)\n",
    "            else:\n",
    "                prediccion = self.regressor.predict(X=np.column_stack((X, exog[i])))\n",
    "                \n",
    "            predicciones[i] = prediccion.ravel()[0]\n",
    "\n",
    "            # Actualizar valores de X. Se descarta la primera posición de X y se\n",
    "            # añade la nueva predicción al final.\n",
    "            X = X.flatten()\n",
    "            X = np.append(X[1:], prediccion)\n",
    "            X = X.reshape(1, -1)\n",
    "\n",
    "\n",
    "        return predicciones\n",
    "    \n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        '''\n",
    "        Asignar nuevos valores a los parámetros del modelo scikitlearn contenido\n",
    "        en el Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Valor de los parámetros del modelo.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.regressor.set_params(**params)\n",
    "        \n",
    "        \n",
    "    def set_n_lags(self, n_lags):\n",
    "        '''\n",
    "        Asignar nuevo valor al atributo `n_lags` del Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_lags : int\n",
    "            Número de lags utilizados como predictores.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.n_lags = n_lags\n",
    "        \n",
    "        \n",
    "def time_series_spliter(y, initial_train_size, steps, allow_incomplete_fold=True):\n",
    "    '''\n",
    "    \n",
    "    Dividir los índices de una serie temporal en múltiples pares train-test.\n",
    "    Se mantiene el orden temporal de los datos y se incrementa en cada iteración\n",
    "    el conjunto de entrenamiento.\n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento. \n",
    "                \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    train : ndarray\n",
    "        Índices del conjunto de entrenamiento.\n",
    "        \n",
    "    test : ndarray\n",
    "        Índices del conjunto de test.\n",
    "        \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    Los índices devueltos equivalen a la posición (empezando por cero), no a los\n",
    "    índices que tenga la serie temporal `y`.\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    folds     = (len(y) - initial_train_size) // steps  + 1\n",
    "    remainder = (len(y) - initial_train_size) % steps    \n",
    "    \n",
    "    for i in range(folds):\n",
    "          \n",
    "        if i < folds - 1:\n",
    "            train_end     = initial_train_size + i * steps    \n",
    "            train_indices = range(train_end)\n",
    "            test_indices  = range(train_end, train_end + steps)\n",
    "            \n",
    "        else:\n",
    "            if remainder != 0 and allow_incomplete_fold:\n",
    "                train_end     = initial_train_size + i * steps  \n",
    "                train_indices = range(train_end)\n",
    "                test_indices  = range(train_end, train_end + remainder)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        yield train_indices, test_indices\n",
    "        \n",
    "\n",
    "def ts_cv_forecaster(forecaster, y, initial_train_size, steps, metric, exog=None,\n",
    "                     allow_incomplete_fold=True):\n",
    "    '''\n",
    "    Validación cruzada de un Forecaster, manteniendo el orden temporal de los\n",
    "    datos e incrementando en cada iteración el conjunto de entrenamiento `steps`\n",
    "    posiciones.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "        Serie temporal de entrenamiento. \n",
    "            \n",
    "    exog : array-like, shape (nº observaviones, )\n",
    "        Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "        predictor/es.\n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    ts_cv_results: \n",
    "        Valor de la métrica obtenido en cada partición.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ts_cv_results = []\n",
    "    \n",
    "    metrics = {\n",
    "        'neg_mean_squared_error': mean_squared_error,\n",
    "        'neg_mean_absolute_error': mean_absolute_error,\n",
    "        'neg_mean_absolute_percentage_error': mean_absolute_percentage_error\n",
    "    }\n",
    "    \n",
    "    metric = metrics[metric]\n",
    "    \n",
    "    splits = time_series_spliter(\n",
    "                y                     = y,\n",
    "                initial_train_size    = initial_train_size,\n",
    "                steps                 = steps,\n",
    "                allow_incomplete_fold = allow_incomplete_fold\n",
    "             )\n",
    "    \n",
    "    for train_index, test_index in splits:\n",
    "        \n",
    "        if exog is None:\n",
    "            forecaster.fit(y=y.iloc[train_index])      \n",
    "            pred = forecaster.predict(steps=len(test_index))\n",
    "        else:\n",
    "            forecaster.fit(y=y.iloc[train_index], exog=exog.iloc[train_index])      \n",
    "            pred = forecaster.predict(steps=len(test_index), exog=exog.iloc[test_index])\n",
    "               \n",
    "        metric_value = metric(\n",
    "                            y_true = y.iloc[test_index],\n",
    "                            y_pred = pred\n",
    "                       )\n",
    "        \n",
    "        ts_cv_results.append(metric_value)\n",
    "                          \n",
    "    return np.array(ts_cv_results)\n",
    "\n",
    "\n",
    "def grid_search_forecaster(forecaster, y, param_grid, initial_train_size, steps,\n",
    "                           metric, exog=None, n_lags_grid=None,\n",
    "                           allow_incomplete_fold=False, return_best=True):\n",
    "    '''\n",
    "    Busqueda exaustiva sobre los hiperparámetros de un Forecaster mediante\n",
    "    validación cruzada.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "        Serie temporal de entrenamiento. \n",
    "        \n",
    "    exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor.\n",
    "    \n",
    "    param_grid : dict\n",
    "        Valores de hiperparámetros sobre los que hacer la búsqueda\n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "        \n",
    "    n_lags_grid : array-like\n",
    "        Valores de `n_lags` sobre los que hacer la búsqueda.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el ultimo conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "    \n",
    "    return_best : devuelve modifica el Forecaster y lo entrena con los mejores\n",
    "                  hiperparámetros encontrados.\n",
    "    Returns \n",
    "    -------\n",
    "    results: pandas.DataFrame\n",
    "        Valor de la métrica obtenido en cada combinación de hiperparámetros.\n",
    "\n",
    "    '''\n",
    "    n_lags_list = []\n",
    "    params_list = []\n",
    "    metric_list = []\n",
    "    \n",
    "    if n_lags_grid is None:\n",
    "        n_lags_grid = [forecaster.n_lags]\n",
    "    \n",
    "    param_grid =  list(ParameterGrid(param_grid))\n",
    "    \n",
    "    for n_lags in tqdm.tqdm(n_lags_grid, desc='loop n_lags_grid', position=0):\n",
    "        \n",
    "        forecaster.set_n_lags(n_lags)\n",
    "        \n",
    "        for params in tqdm.tqdm(param_grid, desc='loop param_grid', position=1, leave=False):\n",
    "\n",
    "            forecaster.set_params(**params)\n",
    "\n",
    "            cv_metrics = ts_cv_forecaster(\n",
    "                            forecaster = forecaster,\n",
    "                            y          = y,\n",
    "                            exog       = exog,\n",
    "                            initial_train_size = initial_train_size,\n",
    "                            steps  = steps,\n",
    "                            metric = metric\n",
    "                         )\n",
    "            \n",
    "            n_lags_list.append(n_lags)\n",
    "            params_list.append(params)\n",
    "            metric_list.append(cv_metrics.mean())\n",
    "            \n",
    "    resultados = pd.DataFrame({\n",
    "                    'n_lags': n_lags_list,\n",
    "                    'params': params_list,\n",
    "                    'metric': metric_list})\n",
    "    \n",
    "    resultados = resultados.sort_values(by='metric', ascending=True)\n",
    "    \n",
    "    if return_best:\n",
    "        best_n_lags = resultados['n_lags'].iloc[0]\n",
    "        best_params = resultados['params'].iloc[0]\n",
    "        logging.info(\"Entrenando Forecaster con los mejores parámetros encontrados:\")\n",
    "        logging.info(f\"n_lags: {best_n_lags}, params: {best_params}\")\n",
    "        forecaster.set_n_lags(best_n_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "            \n",
    "    return resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de datos\n",
    "# ==============================================================================\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/' \\\n",
    "      + 'Estadistica-machine-learning-python/master/data/h2o.csv'\n",
    "datos = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Preparación del dato\n",
    "# ==============================================================================\n",
    "datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y/%m/%d')\n",
    "datos = datos.set_index('fecha')\n",
    "datos = datos.rename(columns={'x': 'y'})\n",
    "datos = datos.asfreq('MS')\n",
    "datos = datos['y']\n",
    "datos = datos.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "# ==============================================================================\n",
    "datos_exog = datos.rolling(window=10, closed='right').mean() + 0.5\n",
    "datos_exog = datos_exog[10:]\n",
    "datos = datos[10:]\n",
    "\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos.plot(ax=ax, label='y')\n",
    "datos_exog.plot(ax=ax, label='variable exógena')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación datos train-test\n",
    "# ==============================================================================\n",
    "steps = 36\n",
    "datos_train = datos[:-steps]\n",
    "datos_test  = datos[-steps:]\n",
    "\n",
    "datos_exog_train = datos_exog[:-steps]\n",
    "datos_exog_test  = datos_exog[-steps:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar forecaster\n",
    "# ==============================================================================\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=RandomForestRegressor(random_state=123),\n",
    "                    n_lags=12\n",
    "                )\n",
    "\n",
    "forecaster_rf.fit(y=datos_train, exog=datos_exog_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "predicciones = forecaster_rf.predict(steps=steps, exog=datos_exog_test)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search de hiperparámetros\n",
    "# ==============================================================================\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=RandomForestRegressor(random_state=123),\n",
    "                    n_lags=12\n",
    "                 )\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 500],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "n_lags_grid = [5, 12, 20]\n",
    "\n",
    "resultados_grid = grid_search_forecaster(\n",
    "                        forecaster  = forecaster_rf,\n",
    "                        y           = datos_train,\n",
    "                        exog        = datos_exog_train,\n",
    "                        param_grid  = param_grid,\n",
    "                        n_lags_grid = n_lags_grid,\n",
    "                        steps       = 10,\n",
    "                        metric      = 'neg_mean_squared_error',\n",
    "                        initial_train_size    = int(len(datos_train)*0.5),\n",
    "                        allow_incomplete_fold = False,\n",
    "                        return_best = True\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados Grid Search\n",
    "# ==============================================================================\n",
    "resultados_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen utilizando una ventana temporal de 20 lags y una configuración de random forest {'max_depth': 3, 'n_estimators': 50}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "\n",
    "Se entrena de nuevo un Forecaster con la configuración óptima encontrada por validación cruzada. Si se indica `return_best = True` en el `grid_search_forecaster()`, se modifica *inplace* el forecaster y se entrena con la mejor combinación de parámetros encontrada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "predicciones = forecaster_rf.predict(steps=steps, exog=datos_exog_test)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting con predictores custom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clases y funciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import tqdm\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "\n",
    "logging.basicConfig(\n",
    "    format = '%(asctime)-5s %(name)-15s %(levelname)-8s %(message)s', \n",
    "    level  = logging.INFO, # Nivel de los eventos que se registran en el logger\n",
    ")\n",
    "\n",
    "class Forecaster():\n",
    "    '''\n",
    "    Combierte un regresor de scikitlearn en un forecaster recursivo (multi-step).\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    n_lags : int, default 1\n",
    "        Número de lags utilizados cómo predictores.\n",
    "        \n",
    "    predictor_transformer: function, default `None`\n",
    "        Función que recibe una serie temporal y devuelve una matriz de predictores\n",
    "        y el valor de la serie temporal asociado. Si `None` se utilizan como\n",
    "        predictores los primeros `n_lags` lags.\n",
    "        \n",
    "    window_size: int, default `None`\n",
    "        Tamaño de la ventana temporal a pasado que necesita `predictor_transformer`\n",
    "        para crear los predictores.\n",
    "\n",
    "    \n",
    "    Attributes\n",
    "    ----------\n",
    "    regressor : scikitlearn regressor\n",
    "        Modelo de regresión de scikitlearn.\n",
    "        \n",
    "    last_lags : array-like, shape (1, n_lags)\n",
    "        Último valor de lags que ha visto el Forecaster al ser entrenado. Se\n",
    "        corresponde con el valor de los lags necesarios para predecir el\n",
    "        siguiente `step` después de los datos de entrenamiento.\n",
    "        \n",
    "    included_exog: bool, default `False`.\n",
    "        Si el Forecaster se ha entrenado utilizando variable/s exógenas.\n",
    "        \n",
    "    predictor_transformer: function, default `None`\n",
    "        Función que recibe una serie temporal y devuelve una matriz de predictores\n",
    "        y el valor de la serie temporal asociado.  Si `None` se utilizan como\n",
    "        predictores los primeros `n_lags` lags.\n",
    "        \n",
    "    window_size: int, default `None`\n",
    "        Tamaño de la ventana temporal a pasado que necesita `predictor_transformer`\n",
    "        para crear los predictores.\n",
    "     \n",
    "    '''\n",
    "    \n",
    "    def __init__(self, regressor, n_lags=1, predictor_transformer=None,\n",
    "                 window_size=None):\n",
    "        \n",
    "        self.regressor = regressor\n",
    "        self.n_lags    = n_lags\n",
    "        self.last_lags = None\n",
    "        self.included_exog = False\n",
    "        self.predictor_transformer = predictor_transformer\n",
    "        self.window_size = window_size\n",
    "        \n",
    "        if self.predictor_transformer is not None and self.window_size is None:\n",
    "            raise Exception(\n",
    "                'Es necesario indicar el window_size si se utiliza predictor_transformer.'\n",
    "            )\n",
    "        \n",
    "    \n",
    "    def create_lags(self, y):\n",
    "        '''\n",
    "        Combierte una serie temporal en una matriz donde, cada valor de y,\n",
    "        está asociado a los lags temporales que le preceden.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        X_data : array-like, shape (nº observaviones, n_lags)\n",
    "            Matriz con el valor de los lags.\n",
    "        \n",
    "        y_data : array-like, shape (nº observaviones - n_lags)\n",
    "            Valores de la variable respuesta.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        # Número de divisiones\n",
    "        n_splits = len(y) - self.n_lags\n",
    "\n",
    "        # Matriz donde almacenar los valore de cada lag\n",
    "        X_data  = np.full(shape=(n_splits, self.n_lags), fill_value=np.nan, dtype= float)\n",
    "        y_data  = np.full(shape=(n_splits, 1), fill_value=np.nan, dtype= float)\n",
    "\n",
    "        for i in range(n_splits):\n",
    "\n",
    "            train_index = np.array(y.index[i : self.n_lags + i])\n",
    "            test_index  = y.index[self.n_lags + i]\n",
    "\n",
    "            X_data[i, :] = y[train_index]\n",
    "            y_data[i]    = y[test_index]\n",
    "\n",
    "        return X_data, y_data\n",
    "    \n",
    "    \n",
    "    def create_predictors(self, y):\n",
    "        '''\n",
    "        Creación de predictores a partir de `y`. Si el Forecaster no tiene definido\n",
    "        una función `predictor_transformer`, se utilizan como predictores los `n_lags`\n",
    "        primeros lags.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        X_data : array-like, shape (nº observaviones, )\n",
    "            Matriz con el valor de los predictores.\n",
    "        \n",
    "        y_data : array-like, shape (nº observaviones)\n",
    "            Variable respuesta\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        if self.predictor_transformer is None:\n",
    "            return self.create_lags(y=y)\n",
    "        else:\n",
    "            return self.predictor_transformer(y=y)\n",
    "\n",
    "        \n",
    "    def fit(self, y, exog=None):\n",
    "        '''\n",
    "        Entrenamiento del Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------        \n",
    "        y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento.\n",
    "            \n",
    "        exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor/es.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self : object\n",
    "               objeto Forecaster entrenado.\n",
    "        \n",
    "        '''       \n",
    "        \n",
    "        X_train, y_train = self.create_predictors(y=y)\n",
    "        \n",
    "        if exog is not None:\n",
    "            self.included_exog = True\n",
    "            self.regressor.fit(\n",
    "                # Se tiene que eliminar de exog las primeras self.n_lags\n",
    "                # posiciones ya que son NaN en X_train.\n",
    "                X=np.column_stack((X_train, exog[self.n_lags:])),\n",
    "                y=y_train\n",
    "            )\n",
    "        else:\n",
    "            self.regressor.fit(X=X_train, y=y_train)\n",
    "        \n",
    "        if self.predictor_transformer is None:\n",
    "            # Se guarda la última ventana temporal de lags de entrenamiento para que \n",
    "            # pueda utilizarse como predictores en la primera iteración del predict().\n",
    "            self.last_lags = np.hstack((X_train[-1, 1:], y_train[-1])).reshape(1, -1)\n",
    "            print(self.last_lags)\n",
    "        \n",
    "        else:\n",
    "            # Se guarda la última ventana temporal de `y` del entrenamiento para \n",
    "            # utilizarla en la creación de predictores en la primera iteración\n",
    "            # del predict().\n",
    "            self.last_window = y_train[-self.window_size:].flatten()\n",
    "            print(self.last_window)\n",
    "            \n",
    "        \n",
    "            \n",
    "    def predict(self, steps, X=None, y=None, exog=None):\n",
    "        '''\n",
    "        Proceso iterativo en la que, cada predicción, se utiliza como\n",
    "        predictor de la siguiente predicción.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "               \n",
    "        steps : int\n",
    "            Número de pasos a futuro que se predicen.\n",
    "            \n",
    "        X : array-like, shape (1, n_lags)\n",
    "            Valor de los predictores con los que se inicia el proceso iterativo\n",
    "            de predicción. Es decir, el valor de los lags para t+1.\n",
    "    \n",
    "            Si `X=None`, se utilizan como predictores iniciales los valores\n",
    "            almacenados en `self.last_lags`, y las predicciones se inician a \n",
    "            continuación de los datos de entrenamiento.\n",
    "        \n",
    "        y : array-like, shape (self.window_size)\n",
    "            Cuando se utiliza `predictor_transformer`, y es la ventana temporal\n",
    "            de la serie `y` necesaria para crear los predictores. Si `y=None`,\n",
    "            se utilizan los valores almacenados en `self.last_window`.\n",
    "            \n",
    "        exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor/es.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        predicciones : np.array, shape (nº observaciones)\n",
    "            Predicciones del modelo.\n",
    "            \n",
    "        '''\n",
    "\n",
    "        if exog is None and self.included_exog:\n",
    "            raise Exception(\n",
    "                \"Forecaster entrenado con variable/s exogena/s. Se tiene \" \\\n",
    "                + \"que aportar esta misma variable en el predict().\"\n",
    "            )\n",
    "            \n",
    "        if y is not None and self.predictor_transformer is not None and len(y) < self.window_size:\n",
    "            raise Exception(\n",
    "                f\"predictor_transformer requiere que `y` tenga como mínimo\"\n",
    "                f\"de {self.window_size} observaciones.\"\n",
    "            )\n",
    "            \n",
    "        if exog is not None:\n",
    "            if isinstance(exog, (pd.Series, list)):\n",
    "                exog = np.array(exog).reshape(-1,1)\n",
    "            \n",
    "\n",
    "        predicciones = np.full(shape=steps, fill_value=np.nan)\n",
    "\n",
    "        if self.predictor_transformer is None:\n",
    "            \n",
    "            if X is None:\n",
    "                X = self.last_lags\n",
    "            \n",
    "            for i in range(steps):\n",
    "                if exog is None:\n",
    "                    prediccion = self.regressor.predict(X=X)\n",
    "                else:\n",
    "                    prediccion = self.regressor.predict(X=np.column_stack((X, exog[i])))\n",
    "\n",
    "                predicciones[i] = prediccion.ravel()[0]\n",
    "\n",
    "                # Actualizar valores de X. Se descarta la primera y se añade la\n",
    "                # nueva predicción al final.\n",
    "                X = X.flatten()\n",
    "                X = np.append(X[1:], prediccion)\n",
    "                X = X.reshape(1, -1)\n",
    "                \n",
    "        else:\n",
    "            \n",
    "            if y is None:\n",
    "                last_window = self.last_window.copy()\n",
    "            else:\n",
    "                last_window = y.copy()\n",
    "                        \n",
    "            for i in range(steps):\n",
    "                # La última observación de last_window debe formar parte de los\n",
    "                # en el cálculo de predictores. Como por defecto create_predictors()\n",
    "                # separa la última predicción en y_train. Se añade al final de\n",
    "                # last_window un valor 0 de relleno.\n",
    "                last_window = np.append(last_window, 0)\n",
    "                X, _ = self.create_predictors(last_window)\n",
    "                X = X[-1].reshape(1, -1)\n",
    "                if exog is None:\n",
    "                    prediccion = self.regressor.predict(X=X)\n",
    "                else:\n",
    "                    prediccion = self.regressor.predict(X=np.column_stack((X, exog[i])))\n",
    "\n",
    "                predicciones[i] = prediccion.ravel()[0]\n",
    "\n",
    "                # Actualizar valores de last_window. Se descarta la primera y se\n",
    "                # añade la nueva predicción al final. Se elimina el 0 de relleno\n",
    "                # que tiene last_window al final.\n",
    "                last_window = np.append(last_window[1:-1], prediccion)\n",
    "\n",
    "        return predicciones\n",
    "    \n",
    "    \n",
    "    def set_params(self, **params):\n",
    "        '''\n",
    "        Asignar nuevos valores a los parámetros del modelo scikitlearn contenido\n",
    "        en el Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        params : dict\n",
    "            Valor de los parámetros del modelo.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.regressor.set_params(**params)\n",
    "        \n",
    "        \n",
    "    def set_n_lags(self, n_lags):\n",
    "        '''\n",
    "        Asignar nuevo valor al atributo `n_lags` del Forecaster.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        n_lags : int\n",
    "            Número de lags utilizados como predictores.\n",
    "\n",
    "        Returns \n",
    "        -------\n",
    "        self\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.n_lags = n_lags\n",
    "        \n",
    "        \n",
    "def time_series_spliter(y, initial_train_size, steps, allow_incomplete_fold=True):\n",
    "    '''\n",
    "    \n",
    "    Dividir los índices de una serie temporal en múltiples pares train-test.\n",
    "    Se mantiene el orden temporal de los datos y se incrementa en cada iteración\n",
    "    el conjunto de entrenamiento.\n",
    "    \n",
    "    Parameters\n",
    "    ----------        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "            Serie temporal de entrenamiento. \n",
    "                \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `True`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "\n",
    "    Yields\n",
    "    ------\n",
    "    train : ndarray\n",
    "        Índices del conjunto de entrenamiento.\n",
    "        \n",
    "    test : ndarray\n",
    "        Índices del conjunto de test.\n",
    "        \n",
    "        \n",
    "    Notes\n",
    "    -----\n",
    "    \n",
    "    Los índices devueltos equivalen a la posición (empezando por cero), no a los\n",
    "    índices que tenga la serie temporal `y`.\n",
    "    '''\n",
    "    \n",
    "  \n",
    "    folds     = (len(y) - initial_train_size) // steps  + 1\n",
    "    remainder = (len(y) - initial_train_size) % steps    \n",
    "    \n",
    "    for i in range(folds):\n",
    "          \n",
    "        if i < folds - 1:\n",
    "            train_end     = initial_train_size + i * steps    \n",
    "            train_indices = range(train_end)\n",
    "            test_indices  = range(train_end, train_end + steps)\n",
    "            \n",
    "        else:\n",
    "            if remainder != 0 and allow_incomplete_fold:\n",
    "                train_end     = initial_train_size + i * steps  \n",
    "                train_indices = range(train_end)\n",
    "                test_indices  = range(train_end, train_end + remainder)\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        yield train_indices, test_indices\n",
    "        \n",
    "\n",
    "def ts_cv_forecaster(forecaster, y, initial_train_size, steps, metric, exog=None,\n",
    "                     allow_incomplete_fold=True):\n",
    "    '''\n",
    "    Validación cruzada de un Forecaster, manteniendo el orden temporal de los\n",
    "    datos e incrementando en cada iteración el conjunto de entrenamiento `steps`\n",
    "    posiciones.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "        Serie temporal de entrenamiento. \n",
    "            \n",
    "    exog : array-like, shape (nº observaviones, )\n",
    "        Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "        predictor/es.\n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el último conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error', 'neg_mean_absolute_error', 'neg_mean_absolute_percentage_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "\n",
    "    Returns \n",
    "    -------\n",
    "    ts_cv_results: \n",
    "        Valor de la métrica obtenido en cada partición.\n",
    "\n",
    "    '''\n",
    "    \n",
    "    ts_cv_results = []\n",
    "    \n",
    "    metrics = {\n",
    "        'neg_mean_squared_error': mean_squared_error,\n",
    "        'neg_mean_absolute_error': mean_absolute_error,\n",
    "        'neg_mean_absolute_percentage_error': mean_absolute_percentage_error\n",
    "    }\n",
    "    \n",
    "    metric = metrics[metric]\n",
    "    \n",
    "    splits = time_series_spliter(\n",
    "                y                     = y,\n",
    "                initial_train_size    = initial_train_size,\n",
    "                steps                 = steps,\n",
    "                allow_incomplete_fold = allow_incomplete_fold\n",
    "             )\n",
    "    \n",
    "    for train_index, test_index in splits:\n",
    "        \n",
    "        if exog is None:\n",
    "            forecaster.fit(y=y.iloc[train_index])      \n",
    "            pred = forecaster.predict(steps=len(test_index))\n",
    "        else:\n",
    "            forecaster.fit(y=y.iloc[train_index], exog=exog.iloc[train_index])      \n",
    "            pred = forecaster.predict(steps=len(test_index), exog=exog.iloc[test_index])\n",
    "               \n",
    "        metric_value = metric(\n",
    "                            y_true = y.iloc[test_index],\n",
    "                            y_pred = pred\n",
    "                       )\n",
    "        \n",
    "        ts_cv_results.append(metric_value)\n",
    "                          \n",
    "    return np.array(ts_cv_results)\n",
    "\n",
    "\n",
    "def grid_search_forecaster(forecaster, y, param_grid, initial_train_size, steps,\n",
    "                           metric, exog=None, n_lags_grid=None,\n",
    "                           allow_incomplete_fold=False, return_best=True):\n",
    "    '''\n",
    "    Busqueda exaustiva sobre los hiperparámetros de un Forecaster mediante\n",
    "    validación cruzada.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    forecaster : object \n",
    "        Objeto de clase Forecaster.\n",
    "        \n",
    "    y : array-like, shape (nº observaviones)\n",
    "        Serie temporal de entrenamiento. \n",
    "        \n",
    "    exog : array-like, shape (nº observaviones, )\n",
    "            Variable/s exógena a la serie temporal que se quiere incluir como\n",
    "            predictor.\n",
    "    \n",
    "    param_grid : dict\n",
    "        Valores de hiperparámetros sobre los que hacer la búsqueda\n",
    "    \n",
    "    initial_train_size: int \n",
    "        Número de observaciones de entrenamiento utilizadas en la primera iteración\n",
    "        de validación.\n",
    "        \n",
    "    steps : int\n",
    "        Número de pasos a futuro que se predicen.\n",
    "        \n",
    "    metric : {'neg_mean_squared_error'}\n",
    "        Métrica utilizada para cuantificar la bondad de ajuste del modelo.\n",
    "        \n",
    "    n_lags_grid : array-like\n",
    "        Valores de `n_lags` sobre los que hacer la búsqueda.\n",
    "        \n",
    "    allow_incomplete_fold : bool, default `False`\n",
    "        Se permite que el ultimo conjunto de test esté incompleto si este\n",
    "        no alcanza `steps` observaciones. De lo contrario, se descartan las\n",
    "        últimas observaciones.\n",
    "    \n",
    "    return_best : devuelve modifica el Forecaster y lo entrena con los mejores\n",
    "                  hiperparámetros encontrados.\n",
    "    Returns \n",
    "    -------\n",
    "    results: pandas.DataFrame\n",
    "        Valor de la métrica obtenido en cada combinación de hiperparámetros.\n",
    "\n",
    "    '''\n",
    "    n_lags_list = []\n",
    "    params_list = []\n",
    "    metric_list = []\n",
    "    \n",
    "    if n_lags_grid is None:\n",
    "        n_lags_grid = [forecaster.n_lags]\n",
    "    \n",
    "    param_grid =  list(ParameterGrid(param_grid))\n",
    "    \n",
    "    for n_lags in tqdm.tqdm(n_lags_grid, desc='loop n_lags_grid', position=0):\n",
    "        \n",
    "        forecaster.set_n_lags(n_lags)\n",
    "        \n",
    "        for params in tqdm.tqdm(param_grid, desc='loop param_grid', position=1, leave=False):\n",
    "\n",
    "            forecaster.set_params(**params)\n",
    "\n",
    "            cv_metrics = ts_cv_forecaster(\n",
    "                            forecaster = forecaster,\n",
    "                            y          = y,\n",
    "                            exog       = exog,\n",
    "                            initial_train_size = initial_train_size,\n",
    "                            steps  = steps,\n",
    "                            metric = metric\n",
    "                         )\n",
    "            \n",
    "            n_lags_list.append(n_lags)\n",
    "            params_list.append(params)\n",
    "            metric_list.append(cv_metrics.mean())\n",
    "            \n",
    "    resultados = pd.DataFrame({\n",
    "                    'n_lags': n_lags_list,\n",
    "                    'params': params_list,\n",
    "                    'metric': metric_list})\n",
    "    \n",
    "    resultados = resultados.sort_values(by='metric', ascending=True)\n",
    "    \n",
    "    if return_best:\n",
    "        best_n_lags = resultados['n_lags'].iloc[0]\n",
    "        best_params = resultados['params'].iloc[0]\n",
    "        print(\"Entrenando Forecaster con los mejores parámetros encontrados:\")\n",
    "        print(f\"n_lags: {best_n_lags}, params: {best_params}\")\n",
    "        forecaster.set_n_lags(best_n_lags)\n",
    "        forecaster.set_params(**best_params)\n",
    "        forecaster.fit(y=y, exog=exog)\n",
    "            \n",
    "    return resultados "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descarga de datos\n",
    "# ==============================================================================\n",
    "url = 'https://raw.githubusercontent.com/JoaquinAmatRodrigo/' \\\n",
    "      + 'Estadistica-machine-learning-python/master/data/h2o.csv'\n",
    "datos = pd.read_csv(url, sep=',')\n",
    "\n",
    "# Preparación del dato\n",
    "# ==============================================================================\n",
    "datos['fecha'] = pd.to_datetime(datos['fecha'], format='%Y/%m/%d')\n",
    "datos = datos.set_index('fecha')\n",
    "datos = datos.rename(columns={'x': 'y'})\n",
    "datos = datos.asfreq('MS')\n",
    "datos = datos['y']\n",
    "datos = datos.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datos\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos.plot(ax=ax, label='y')\n",
    "datos_exog.plot(ax=ax, label='variable exógena')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separación datos train-test\n",
    "# ==============================================================================\n",
    "steps = 36\n",
    "datos_train = datos[:-steps]\n",
    "datos_test  = datos[-steps:]\n",
    "\n",
    "datos_exog_train = datos_exog[:-steps]\n",
    "datos_exog_test  = datos_exog[-steps:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictores\n",
    "<br>\n",
    "\n",
    "Para este ejemplo, además de los 10 primeros lasgs, se añade como predictor una ventana móvil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictores_custom(y):\n",
    "    \n",
    "    # Creación de lags\n",
    "    X_train = pd.DataFrame({'y':y.copy()})\n",
    "    for i in range(12, 0, -1):\n",
    "        X_train[f'lag_{i}'] = X_train['y'].shift(i)\n",
    "        \n",
    "    # Media movil 30. El shift es necesario para no incluir el valor actual\n",
    "    # en el cálculo\n",
    "    #X_train['roll_mean'] = X_train['y'].rolling(30).mean().shift(1)\n",
    "    \n",
    "    X_train = X_train.dropna()\n",
    "    y_train = X_train['y'].to_numpy()\n",
    "    X_train = X_train.drop(columns='y').to_numpy()  \n",
    "    \n",
    "    return X_train, y_train       \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forecaster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar forecaster\n",
    "# ==============================================================================\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor   = RandomForestRegressor(random_state=123),\n",
    "                    n_lags      = 12,\n",
    "                    predictor_transformer = predictores_custom,\n",
    "                    window_size = 13\n",
    "                )\n",
    "\n",
    "forecaster_rf.fit(y=datos_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_custom(np.array([0.85680282, 1.00159317, 0.99486433, 1.134432,   1.181011,   1.216037,   1.257238,\n",
    "  1.17069,    0.597639,   0.65259,    0.670505,   0.695248,   0.842263, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictores_custom(np.array([0.85680282, 1.00159317, 0.99486433, 1.134432,   1.181011,   1.216037,   1.257238,\n",
    "  1.17069,    0.597639,   0.65259,    0.670505,   0.695248,   0.842263, 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "predicciones = forecaster_rf.predict(steps=steps)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error predictores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid search de hiperparámetros\n",
    "# ==============================================================================\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=RandomForestRegressor(random_state=123),\n",
    "                    n_lags=12\n",
    "                 )\n",
    "\n",
    "param_grid = {'n_estimators': [50, 100, 500],\n",
    "              'max_depth': [3, 5, 10]}\n",
    "\n",
    "n_lags_grid = [5, 12, 20]\n",
    "\n",
    "resultados_grid = grid_search_forecaster(\n",
    "                        forecaster  = forecaster_rf,\n",
    "                        y           = datos_train,\n",
    "                        exog        = datos_exog_train,\n",
    "                        param_grid  = param_grid,\n",
    "                        n_lags_grid = n_lags_grid,\n",
    "                        steps       = 10,\n",
    "                        metric      = 'neg_mean_squared_error',\n",
    "                        initial_train_size    = int(len(datos_train)*0.5),\n",
    "                        allow_incomplete_fold = False\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resultados Grid Search\n",
    "# ==============================================================================\n",
    "resultados_grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mejores resultados se obtienen utilizando una ventana temporal de 20 lags y una configuración de random forest {'max_depth': 3, 'n_estimators': 50}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelo final\n",
    "\n",
    "Se entrena de nuevo un Forecaster con la configuración optima encontrada por validación cruzada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear y entrenar forecaster\n",
    "# ==============================================================================\n",
    "regressor = RandomForestRegressor(max_depth=3, n_estimators=50, random_state=123)\n",
    "\n",
    "forecaster_rf = Forecaster(\n",
    "                    regressor=regressor,\n",
    "                    n_lags=20\n",
    "                )\n",
    "\n",
    "forecaster_rf.fit(y=datos_train, exog=datos_exog_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicciones\n",
    "# ==============================================================================\n",
    "predicciones = forecaster_rf.predict(steps=steps, exog=datos_exog_test)\n",
    "# Se añade el índice a las predicciones\n",
    "predicciones = pd.Series(data=predicciones, index=datos_test.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráfico\n",
    "# ==============================================================================\n",
    "fig, ax=plt.subplots(figsize=(9, 4))\n",
    "datos_train.plot(ax=ax, label='train')\n",
    "datos_test.plot(ax=ax, label='test')\n",
    "predicciones.plot(ax=ax, label='predicciones')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error\n",
    "# ==============================================================================\n",
    "error_mse = mean_squared_error(\n",
    "                y_true = datos_test,\n",
    "                y_pred = predicciones\n",
    "            )\n",
    "print(f\"Error de test (mse) {error_mse}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información de sesión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sinfo import sinfo\n",
    "sinfo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografía\n",
    "<br>\n",
    "\n",
    "Hyndman, R.J., & Athanasopoulos, G. (2018) Forecasting: principles and practice, 2nd edition, OTexts: Melbourne, Australia. [libro](https://otexts.com/fpp2/)\n",
    "\n",
    "Python Data Science Handbook by Jake VanderPlas [libro](https://www.amazon.es/gp/product/1491912057/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=cienciadedato-21&creative=24630&linkCode=as2&creativeASIN=1491912057&linkId=73620d22f9d4a0a76d27592dabf13c83)\n",
    "\n",
    "Python for Finance: Mastering Data-Driven Finance [libro](https://www.amazon.es/gp/product/1492024333/ref=as_li_qf_asin_il_tl?ie=UTF8&tag=cienciadedato-21&creative=24630&linkCode=as2&creativeASIN=1492024333&linkId=70c3175ad015970cd1c2328b7a40a055)\n",
    "\n",
    "[Markus Löning, Anthony Bagnall, Sajaysurya Ganesh, Viktor Kazakov, Jason Lines, Franz Király (2019): “sktime: A Unified Interface for Machine Learning with Time Series”](http://learningsys.org/neurips19/assets/papers/sktime_ml_systems_neurips2019.pdf)\n",
    "\n",
    "[Markus Löning, Tony Bagnall, Sajaysurya Ganesh, George Oastler, Jason Lines, ViktorKaz, …, Aadesh Deshmukh (2020). alan-turing-institute/sktime. Zenodo. http://doi.org/10.5281/zenodo.3749000](https://github.com/alan-turing-institute/sktime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "hide_input": true,
    "remove_cell": true,
    "tags": [
     "\"hide_input\""
    ]
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<style>\n",
    ".text_cell_render p {\n",
    "    text-align: justify;\n",
    "    font-family: 'Open Sans','Helvetica Neue',Helvetica,Arial,sans-serif;\n",
    "    #font-size: 16px;\n",
    "    line-height: 1.5;\n",
    "    font-weight: 400;\n",
    "    text-shadow: none;\n",
    "    color: #333333;\n",
    "    text-rendering: optimizeLegibility;\n",
    "    letter-spacing: +0.1px;\n",
    "    margin-bottom: 1.15rem;\n",
    "    font-size: 1.15em\n",
    "}\n",
    "\n",
    "#notebook-container {\n",
    "    background-color: #fcfcfc;\n",
    "}\n",
    "\n",
    "div.inner_cell {\n",
    "    margin-right: 5%;\n",
    "}\n",
    "\n",
    ".output_png {\n",
    "        display: table-cell;\n",
    "        text-align: center;\n",
    "        vertical-align: middle;\n",
    "}\n",
    "\n",
    ".rendered_html code {\n",
    "    background-color: #f2f2f2;\n",
    "    font-family: monospace;\n",
    "    color: #a20505;\n",
    "    font-size: 15px;\n",
    "    #font-size: 1em;\n",
    "    padding: 1px 1px;\n",
    "    border: solid;\n",
    "    border-color: darkgray;\n",
    "    border-width: thin;\n",
    "}\n",
    "\n",
    ".rendered_html h1 {\n",
    "    padding-top: 50px;\n",
    "}\n",
    "\n",
    ".rendered_html h2 {\n",
    "    font-size: 30px\n",
    "    margin-top: 0;\n",
    "    font-size: 2.488em;\n",
    "}\n",
    "\n",
    ".rendered_html h3 {\n",
    "    font-size: 25px;\n",
    "}\n",
    "\n",
    ".rendered_html h4 {\n",
    "    font-size: 20px;\n",
    "}\n",
    "\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Cómo citar este documento?**\n",
    "\n",
    "<p style=\"text-align:left\"><font size=\"3\" color=\"#555\">\n",
    "Forecasting series temporales con Python y Scikitlearn by Joaquín Amat Rodrigo, available under a Attribution 4.0 International (CC BY 4.0) at https://www.cienciadedatos.net\n",
    "    \n",
    "</font></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p><strong>¿Te ha gustado el artículo? Tu ayuda es importante</strong></p>\n",
    "\n",
    "<p style=\"text-align:left\"><font size=\"3\" color=\"#555\">\n",
    "Mantener un sitio web tiene unos costes elevados, tu contribución me ayudará a seguir generando contenido divulgativo gratuito. ¡Muchísimas gracias!</font>\n",
    "<form action=\"https://www.paypal.com/donate\" method=\"post\" target=\"_top\">\n",
    "  <input type=\"hidden\" name=\"hosted_button_id\" value=\"6NULYFYDKFTQL\" />\n",
    "  <input type=\"image\" src=\"https://www.paypalobjects.com/en_US/ES/i/btn/btn_donateCC_LG.gif\" border=\"0\" name=\"submit\" title=\"PayPal - The safer, easier way to pay online!\" alt=\"Donate with PayPal button\" />\n",
    "  <img alt=\"\" border=\"0\" src=\"https://www.paypal.com/en_ES/i/scr/pixel.gif\" width=\"1\" height=\"1\" />\n",
    "  </form>\t\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\"><img alt=\"Creative Commons Licence\" style=\"border-width:0\" src=\"https://i.creativecommons.org/l/by/4.0/88x31.png\" /></a><br />This work by  Joaquín Amat Rodrigo is licensed under a <a rel=\"license\" href=\"http://creativecommons.org/licenses/by/4.0/\">Creative Commons Attribution 4.0 International License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cienciadedatos",
   "language": "python",
   "name": "cienciadedatos"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de contenidos",
   "title_sidebar": "Tabla de contenidos",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "166.75px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "144.391px",
    "left": "1478px",
    "right": "20px",
    "top": "126px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
